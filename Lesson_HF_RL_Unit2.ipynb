{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPh/6UaIbTfjG/PQz2yG+Lu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Art-phys/Lesson_HF_LR/blob/main/Lesson_HF_RL_Unit2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–°–°–´–õ–ö–ê –ù–ê –û–†–ò–ì–ò–ù–ê–õ:\n",
        "\n",
        "https://colab.research.google.com/github/huggingface/deep-rl-class/blob/master/notebooks/unit2/unit2.ipynb#scrollTo=njb_ProuHiOe\n",
        "\n",
        "@huggingface\n",
        "\n",
        "@simoninithomas"
      ],
      "metadata": {
        "id": "XbSFRQlIZ84s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# –ë–ª–æ–∫ 2: Q-Learning —Å FrozenLake-v1 ‚õÑ –∏ Taxi-v3 üöï\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit3/thumbnail.jpg\" alt=\"Unit 2 Thumbnail\" width=\"70%\">\n",
        "\n",
        "–í —ç—Ç–æ–º –±–ª–æ–∫–Ω–æ—Ç–µ **–≤—ã –±—É–¥–µ—Ç–µ —Å –Ω—É–ª—è –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞—Ç—å —Å–≤–æ–π –ø–µ—Ä–≤—ã–π –æ–±—É—á–∞—é—â–∏–π –∞–≥–µ–Ω—Ç —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º** –∏–≥—Ä–∞—Ç—å –≤ Frozen Lake ‚ùÑÔ∏è –∏—Å–ø–æ–ª—å–∑—É—è Q-Learning, –¥–µ–ª–∏—Ç—å—Å—è –∏–º —Å —Å–æ–æ–±—â–µ—Å—Ç–≤–æ–º –∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è–º–∏.\n",
        "\n",
        "\n",
        "‚¨áÔ∏è –í–æ—Ç –ø—Ä–∏–º–µ—Ä —Ç–æ–≥–æ, —á–µ–≥–æ **–≤—ã –¥–æ—Å—Ç–∏–≥–Ω–µ—Ç–µ –≤—Å–µ–≥–æ –∑–∞ –ø–∞—Ä—É –º–∏–Ω—É—Ç.** ‚¨áÔ∏è"
      ],
      "metadata": {
        "id": "WdAw4fP2XfqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit3/envs.gif\" alt=\"Environments\" width=\"70%\"/>"
      ],
      "metadata": {
        "id": "Y2H8aqyWXrhw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###üéÆ –û–∫—Ä—É–∂–∞—é—â–∏–µ —Å—Ä–µ–¥—ã: \n",
        "\n",
        "- [FrozenLake-v1](https://www.gymlibrary.dev/environments/toy_text/frozen_lake/)\n",
        "- [Taxi-v3](https://www.gymlibrary.dev/environments/toy_text/taxi/)\n",
        "\n",
        "###üìö RL-–ë–∏–±–ª–∏–æ—Ç–µ–∫–∏: \n",
        "\n",
        "- Python and NumPy\n",
        "- [Gym](https://www.gymlibrary.dev/)"
      ],
      "metadata": {
        "id": "ZKtqtnOrYxuN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## –í —ç—Ç–æ–º –±–ª–æ–∫–Ω–æ—Ç–µ –í—ã üèÜ:\n",
        "\n",
        "- –ù–∞—É—á–∏—Ç–µ—Å—å –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è **—Ç—Ä–µ–Ω–∞–∂–µ—Ä–Ω—ã–º –∑–∞–ª–æ–º (Gym)**, –±–∏–±–ª–∏–æ—Ç–µ–∫–æ–π –æ–∫—Ä—É–∂–∞—é—â–µ–π —Å—Ä–µ–¥—ã.\n",
        "- –ù–∞—É—á–∏—Ç–µ—Å—å —Å –Ω—É–ª—è –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞—Ç—å Q-Learning –∞–≥–µ–Ω—Ç–∞.\n",
        "- –ù–∞—É—á–∏—Ç–µ—Å—å **–æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å —Å–≤–æ–µ–≥–æ –æ–±—É—á–µ–Ω–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞ –∏ –∫–æ–¥ –≤ —Ü–µ–Ω—Ç—Ä** —Å —Ö–æ—Ä–æ—à–∏–º –≤–∏–¥–µ–æ–ø–æ–≤—Ç–æ—Ä–æ–º –∏ –æ—Ü–µ–Ω–æ—á–Ω—ã–º –±–∞–ª–ª–æ–º üî• ."
      ],
      "metadata": {
        "id": "uwcMD11-ZXVE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## –≠—Ç–æ—Ç –±–ª–æ–∫–Ω–æ—Ç –≤–∑—è—Ç –∏–∑ –∫—É—Ä—Å–∞ –æ–±—É—á–µ–Ω–∏—è —Å –≥–ª—É–±–æ–∫–∏–º –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/deep-rl-course-illustration.jpg\" alt=\"Deep RL Course illustration\" width=\"70%\"/>"
      ],
      "metadata": {
        "id": "CJREpQ_fb9u6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "–í —ç—Ç–æ–º –±–µ—Å–ø–ª–∞—Ç–Ω–æ–º –∫—É—Ä—Å–µ –≤—ã –±—É–¥–µ—Ç–µ:\n",
        "\n",
        "- üìñ –ò–∑—É—á–∞—Ç—å –≥–ª—É–±–æ–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –≤ **—Ç–µ–æ—Ä–∏–∏ –∏ –Ω–∞ –ø—Ä–∞–∫—Ç–∏–∫–µ**.\n",
        "- üßë üíª –ù–∞—É—á–∏—Ç–µ—Å—å **–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∏–∑–≤–µ—Å—Ç–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ Deep RL**, —Ç–∞–∫–∏–µ –∫–∞–∫ Stable Baselines3, RL Baselines3 Zoo, CleanRL –∏ Sample Factory 2.0.\n",
        "- ü§ñ –¢—Ä–µ–Ω–∏—Ä–æ–≤–∞—Ç—å **–∞–≥–µ–Ω—Ç–æ–≤ –≤ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —É—Å–ª–æ–≤–∏—è—Ö**\n",
        "\n",
        "–ü–æ —Å—Å—ã–ª–∫–µ –í—ã –º–æ–∂–∏—Ç–µ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å üìö —É—á–µ–±–Ω—É—é –ø—Ä–æ–≥—Ä–∞–º–º—É üëâ https://simoninithomas.github.io/deep-rl-course"
      ],
      "metadata": {
        "id": "hcl0ZlSWcVwg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–µ —É—Å–ª–æ–≤–∏—è üèóÔ∏è\n",
        "–ü—Ä–µ–∂–¥–µ —á–µ–º –ø–æ–≥—Ä—É–∑–∏—Ç—å—Å—è –≤ –±–ª–æ–∫–Ω–æ—Ç, –≤–∞–º –Ω—É–∂–Ω–æ:\n",
        "\n",
        "üî≤ üìö **[–ü—Ä–æ—á–∏—Ç–∞—Ç—å –ë–ª–æ–∫2 Q-Learning](https://huggingface.co/deep-rl-course/unit2/introduction)** ü§ó"
      ],
      "metadata": {
        "id": "wGj2Vm-Sdbba"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## –ù–µ–±–æ–ª—å—à–æ–π –æ–±–∑–æ—Ä Q-Learning"
      ],
      "metadata": {
        "id": "AofjjWMQeKFB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- *Q-Learning* **- —ç—Ç–æ –∞–ª–≥–æ—Ä–∏—Ç–º RL (–û–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º), –∫–æ—Ç–æ—Ä—ã–π** \n",
        "\n",
        "  - –û–±—É—á–∞–µ—Ç *Q-—Ñ—É–Ω–∫—Ü–∏—é*, **—Ñ—É–Ω–∫—Ü–∏—é –¥–µ–π—Å—Ç–≤–∏—è-–∑–Ω–∞—á–µ–Ω–∏—è(action-value)**, –∫–æ—Ç–æ—Ä–∞—è —Å–æ–¥–µ—Ä–∂–∏—Ç –≤ –∫–∞—á–µ—Å—Ç–≤–µ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–π –ø–∞–º—è—Ç–∏ *Q-—Ç–∞–±–ª–∏—Ü—É*, —Å–æ–¥–µ—Ä–∂–∞—â—É—é –≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø–∞—Ä—ã **—Å–æ—Å—Ç–æ—è–Ω–∏–µ-–¥–µ–π—Å—Ç–≤–∏–µ(state-action).**\n",
        "    \n",
        " - –£—á–∏—Ç—ã–≤–∞—è —Å–æ—Å—Ç–æ—è–Ω–∏–µ (S)  –∏ –¥–µ–π—Å—Ç–≤–∏–µ (A), –Ω–∞—à–∞ Q-—Ñ—É–Ω–∫—Ü–∏—è **–±—É–¥–µ—Ç –∏—Å–∫–∞—Ç—å –≤ —Å–≤–æ–µ–π Q-—Ç–∞–±–ª–∏—Ü–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ.**\n",
        "    \n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit3/Q-function-2.jpg\" alt=\"Q function\"  width=\"70%\"/>\n",
        "\n",
        "- –ö–æ–≥–¥–∞ –æ–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ, —É –Ω–∞—Å –µ—Å—Ç—å –æ–ø—Ç–∏–º–∞–ª—å–Ω–∞—è **Q-—Ñ—É–Ω–∫—Ü–∏—è**, –∞ –∑–Ω–∞—á–∏—Ç, –∏ –æ–ø—Ç–∏–º–∞–ª—å–Ω–∞—è **Q-—Ç–∞–±–ª–∏—Ü–∞.**\n",
        "\n",
        "- –ò –µ—Å–ª–∏ —É –Ω–∞—Å –µ—Å—Ç—å –æ–ø—Ç–∏–º–∞–ª—å–Ω–∞—è **Q-—Ñ—É–Ω–∫—Ü–∏—è**, —É –Ω–∞—Å\n",
        "–µ—Å—Ç—å –æ–ø—Ç–∏–º–∞–ª—å–Ω–∞—è –ø–æ–ª–∏—Ç–∏–∫–∞, –ø–æ—Å–∫–æ–ª—å–∫—É –º—ã **–∑–Ω–∞–µ–º –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è, –∫–∞–∫–∏–µ –¥–µ–π—Å—Ç–≤–∏—è –ª—É—á—à–µ –ø—Ä–µ–¥–ø—Ä–∏–Ω—è—Ç—å.**\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit3/link-value-policy.jpg\" alt=\"Link value policy\"  width=\"70%\"/>\n",
        "\n",
        "\n",
        "–ù–æ –≤–Ω–∞—á–∞–ª–µ –Ω–∞—à–∞ **Q-—Ç–∞–±–ª–∏—Ü–∞ –±–µ—Å–ø–æ–ª–µ–∑–Ω–∞, –ø–æ—Å–∫–æ–ª—å–∫—É –æ–Ω–∞ –¥–∞–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è –∫–∞–∂–¥–æ–π –ø–∞—Ä—ã —Å–æ—Å—Ç–æ—è–Ω–∏–µ-–¥–µ–π—Å—Ç–≤–∏–µ** (–Ω–∞ –Ω–∞—á–∞–ª—å–Ω–æ–º —ç—Ç–∞–ø–µ –º—ã –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º Q-—Ç–∞–±–ª–∏—Ü—É –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ 0). –ù–æ –ø–æ –º–µ—Ä–µ —Ç–æ–≥–æ, –∫–∞–∫ –º—ã –±—É–¥–µ–º –∏–∑—É—á–∞—Ç—å –æ–∫—Ä—É–∂–∞—é—â—É—é —Å—Ä–µ–¥—É –∏ –æ–±–Ω–æ–≤–ª—è—Ç—å –Ω–∞—à—É Q-—Ç–∞–±–ª–∏—Ü—É, —ç—Ç–æ –±—É–¥–µ—Ç –¥–∞–≤–∞—Ç—å –Ω–∞–º –≤—Å–µ –ª—É—á—à–∏–µ –∏ –ª—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/unit2/q-learning.jpeg\" alt=\"q-learning.jpeg\" width=\"70%\"/>\n",
        "\n",
        "–≠—Ç–æ –ø—Å–µ–≤–¥–æ–∫–æ–¥ Q-Learning:\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit3/Q-learning-2.jpg\" alt=\"Q-Learning\" width=\"70%\"/>"
      ],
      "metadata": {
        "id": "YJefH3lpeSNa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mKDLPd_Nju2N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# –î–∞–≤–∞–π—Ç–µ –∑–∞–∫–æ–¥–∏—Ä—É–µ–º –Ω–∞—à –ø–µ—Ä–≤—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º(RL) üöÄ"
      ],
      "metadata": {
        "id": "7JVRbS4Vlan0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ß—Ç–æ–±—ã –ø–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç—å —ç—Ç–æ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –¥–ª—è [–ø—Ä–æ—Ü–µ—Å—Å–∞ —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏](https://huggingface.co/deep-rl-course/en/unit0/introduction#certification-process), –≤–∞–º –Ω—É–∂–Ω–æ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–≤–æ—é –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å —Ç–∞–∫—Å–∏ –≤ —Ü–µ–Ω—Ç—Ä –∏ **–ø–æ–ª—É—á–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç >= 4,5**.\n",
        "\n",
        "–ß—Ç–æ–±—ã —É–∑–Ω–∞—Ç—å —Å–≤–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç, –ø–µ—Ä–µ–π–¥–∏—Ç–µ –≤ [—Ç–∞–±–ª–∏—Ü—É –ª–∏–¥–µ—Ä–æ–≤](https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard) –∏ –Ω–∞–π–¥–∏—Ç–µ —Å–≤–æ—é –º–æ–¥–µ–ª—å, **the result = mean_reward - std of reward**\n",
        "\n",
        "–î–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø—Ä–æ—Ü–µ—Å—Å–µ —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ –æ–∑–Ω–∞–∫–æ–º—å—Ç–µ—Å—å —Å —ç—Ç–∏–º —Ä–∞–∑–¥–µ–ª–æ–º üëâ https://huggingface.co/deep-rl-course/en/unit0/introduction#certification-process"
      ],
      "metadata": {
        "id": "x7d_RVS1lmlS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –∏ —Å–æ–∑–¥–∞–π—Ç–µ –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–π –¥–∏—Å–ø–ª–µ–π üîΩ\n",
        "\n",
        "–í –∑–∞–ø–∏—Å–Ω–æ–π –±–ª–æ–∫–Ω–æ—Ç–µ –Ω–∞–º –Ω—É–∂–Ω–æ –±—É–¥–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø–æ–≤—Ç–æ—Ä –≤–∏–¥–µ–æ.  –î–ª—è —ç—Ç–æ–≥–æ —Å –ø–æ–º–æ—â—å—é Colab **—Å–æ–∑–¥–∞–¥–∏–º –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–π —ç–∫—Ä–∞–Ω –¥–ª—è —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥–∞ —Å—Ä–µ–¥—ã** (–∏ –∑–∞–ø–∏—Å–∏ –∫–∞–¥—Ä–æ–≤).\n",
        "\n",
        "–°–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ, —Å–ª–µ–¥—É—é—â–∞—è —è—á–µ–π–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫–∏, —Å–æ–∑–¥–∞—Å—Ç –∏ –∑–∞–ø—É—Å—Ç–∏—Ç –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–π —ç–∫—Ä–∞–Ω üñ•\n",
        "\n",
        "–ú—ã —É—Å—Ç–∞–Ω–æ–≤–∏–º:\n",
        "\n",
        "- `gym`: –°–æ–¥–µ—Ä–∂–∏—Ç —Å—Ä–µ–¥—ã FrozenLake-v1 ‚õÑ –∏ Taxi-v3 üöï . –ú—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º `gym==0.24`, —Ç–∞–∫ –∫–∞–∫ –æ–Ω —Å–æ–¥–µ—Ä–∂–∏—Ç —Ö–æ—Ä–æ—à—É—é –≤–µ—Ä—Å–∏—é –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ Taxi-v3.\n",
        "- `pygame`: –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ FrozenLake-v1 –∏ Taxi-v3.\n",
        "- `numpy`:–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–∞—à–µ–π Q-—Ç–∞–±–ª–∏—Ü—ã.\n",
        "\n",
        "Hugging Face Hub ü§ó —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–∞–∫ —Ü–µ–Ω—Ç—Ä, –≥–¥–µ –ª—é–±–æ–π –∂–µ–ª–∞—é—â–∏–π –º–æ–∂–µ—Ç –¥–µ–ª–∏—Ç—å—Å—è –º–æ–¥–µ–ª—è–º–∏ –∏ –Ω–∞–±–æ—Ä–∞–º–∏ –¥–∞–Ω–Ω—ã—Ö –∏ –∏–∑—É—á–∞—Ç—å –∏—Ö. –í –Ω–µ–º –µ—Å—Ç—å —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≤–µ—Ä—Å–∏—è–º–∏, –º–µ—Ç—Ä–∏–∫–∏, –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –∏ –¥—Ä—É–≥–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–∑–≤–æ–ª—è—Ç –≤–∞–º –ª–µ–≥–∫–æ —Å–æ—Ç—Ä—É–¥–Ω–∏—á–∞—Ç—å —Å –¥—Ä—É–≥–∏–º–∏.\n",
        "\n",
        "–í—ã –º–æ–∂–µ—Ç–µ —É–≤–∏–¥–µ—Ç—å –∑–¥–µ—Å—å –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ Deep RL (–µ—Å–ª–∏ –æ–Ω–∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç Q Learning) üëâ https://huggingface.co/models?other=q-learning"
      ],
      "metadata": {
        "id": "PyhkR-FqmRSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit2/requirements-unit2.txt"
      ],
      "metadata": {
        "id": "IQcbB2aPoKv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!sudo apt-get update\n",
        "!apt install python-opengl ffmpeg xvfb\n",
        "!pip3 install pyvirtualdisplay"
      ],
      "metadata": {
        "id": "xJHEDDD7oNXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ß—Ç–æ–±—ã —É–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –Ω–æ–≤—ã–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è, **–∏–Ω–æ–≥–¥–∞ —Ç—Ä–µ–±—É–µ—Ç—Å—è –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å notebook runtime**. –°–ª–µ–¥—É—é—â–∞—è —è—á–µ–π–∫–∞ –ø—Ä–∏–≤–µ–¥–µ—Ç –∫ —Å–±–æ—é —Å—Ä–µ–¥—ã –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è **, –ø–æ—ç—Ç–æ–º—É –≤–∞–º –Ω—É–∂–Ω–æ –±—É–¥–µ—Ç —Å–Ω–æ–≤–∞ –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∏ –∑–∞–ø—É—Å—Ç–∏—Ç—å –∫–æ–¥, –Ω–∞—á–∏–Ω–∞—è –æ—Ç—Å—é–¥–∞**. –ë–ª–∞–≥–æ–¥–∞—Ä—è —ç—Ç–æ–º—É —Ç—Ä—é–∫—É, **–º—ã —Å–º–æ–∂–µ–º –∑–∞–ø—É—Å—Ç–∏—Ç—å –Ω–∞—à –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–π —ç–∫—Ä–∞–Ω.**"
      ],
      "metadata": {
        "id": "iM3FIcQmoHt5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "id": "ICh2VwRgovjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# –í–∏—Ä—Ç—É–∞–ª—å–Ω—ã–π –¥–∏—Å–ø–ª–µ–π\n",
        "from pyvirtualdisplay import Display\n",
        "\n",
        "virtual_display = Display(visible=0, size=(1400, 900))\n",
        "virtual_display.start()"
      ],
      "metadata": {
        "id": "yGueln6To0ZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## –ò–º–ø–æ—Ä—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –ø–∞–∫–µ—Ç–æ–≤ üì¶\n",
        "\n",
        "–í –¥–æ–ø–æ–ª–Ω–µ–Ω–∏–µ –∫ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–º –±–∏–±–ª–∏–æ—Ç–µ–∫–∞–º –º—ã —Ç–∞–∫–∂–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º:\n",
        "\n",
        "- `random`: –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–ª—É—á–∞–π–Ω—ã—Ö —á–∏—Å–µ–ª (—ç—Ç–æ –±—É–¥–µ—Ç –ø–æ–ª–µ–∑–Ω–æ –¥–ª—è –ø–æ–ª–∏—Ç–∏–∫–∏ epsilon-gready).\n",
        "- `imageio`: –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –≤–∏–¥–µ–æ."
      ],
      "metadata": {
        "id": "dM2D-NGPo-k3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "import random\n",
        "import imageio\n",
        "import os\n",
        "import tqdm\n",
        "\n",
        "import pickle5 as pickle\n",
        "from tqdm.notebook import tqdm"
      ],
      "metadata": {
        "id": "SRlHh5RupNRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "–¢–µ–ø–µ—Ä—å –º—ã –≥–æ—Ç–æ–≤—ã –∑–∞–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å –Ω–∞—à –∞–ª–≥–æ—Ä–∏—Ç–º Q-Learning üî•"
      ],
      "metadata": {
        "id": "dqkVMEpNpVCB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# –ß–∞—Å—Ç—å 1: –ó–∞–º–µ—Ä–∑—à–µ–µ –æ–∑–µ—Ä–æ ‚õÑ (–Ω–µ —Å–∫–æ–ª—å–∑–∫–∞—è –≤–µ—Ä—Å–∏—è)"
      ],
      "metadata": {
        "id": "hxvqX1jtpYWP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## –°–æ–∑–¥–∞–π—Ç–µ [—Å—Ä–µ–¥—É –∑–∞–º–µ—Ä–∑—à–µ–≥–æ –æ–∑–µ—Ä–∞ ‚õÑ ](https://www.gymlibrary.dev/environments/toy_text/frozen_lake/)\n",
        "---\n",
        "\n",
        "üí° –•–æ—Ä–æ—à–∞—è –ø—Ä–∏–≤—ã—á–∫–∞: –ø—Ä–∏ –Ω–∞—á–∞–ª–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Å—Ä–µ–¥—ã, –∏–∑—É—á–∞—Ç—å –µ–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é\n",
        "\n",
        "üëâ https://www.gymlibrary.dev/environments/toy_text/frozen_lake/\n",
        "\n",
        "---\n",
        "\n",
        "–ú—ã —Å–æ–±–∏—Ä–∞–µ–º—Å—è –æ–±—É—á–∏—Ç—å –Ω–∞—à–µ–≥–æ –∞–≥–µ–Ω—Ç–∞ Q-Learning **–ø–µ—Ä–µ—Ö–æ–¥–∏—Ç—å –∏–∑ –Ω–∞—á–∞–ª—å–Ω–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è (S) –≤ —Ü–µ–ª–µ–≤–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ (G), —Å—Ç—É–ø–∞—è —Ç–æ–ª—å–∫–æ –ø–æ –∑–∞–º–æ—Ä–æ–∂–µ–Ω–Ω—ã–º –ø–ª–∏—Ç–∫–∞–º (F) –∏ –∏–∑–±–µ–≥–∞—è —è–º (H)**.\n",
        "\n",
        "–£ –Ω–∞—Å –º–æ–∂–µ—Ç –±—ã—Ç—å –¥–≤–∞ —Ä–∞–∑–º–µ—Ä–∞ —Å—Ä–µ–¥—ã:\n",
        "\n",
        "- `map_name=\"4x4\"`: –≤–µ—Ä—Å–∏—è —Å —Å–µ—Ç–∫–æ–π 4—Ö4\n",
        "- `map_name=\"8x8\"`: –≤–µ—Ä—Å–∏—è —Å —Å–µ—Ç–∫–æ–π 8—Ö8\n",
        "\n",
        "\n",
        "–û–∫—Ä—É–∂–∞—é—â–∞—è —Å—Ä–µ–¥–∞ –∏–º–µ–µ—Ç –¥–≤–∞ —Ä–µ–∂–∏–º–∞:\n",
        "\n",
        "- `is_slippery=False`: –ê–≥–µ–Ω—Ç –≤—Å–µ–≥–¥–∞ –¥–≤–∏–∂–µ—Ç—Å—è **–≤ –∑–∞–¥–∞–Ω–Ω–æ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏** –∏–∑-–∑–∞ –Ω–µ —Å–∫–æ–ª—å–∑–∫–æ–π –ø—Ä–∏—Ä–æ–¥—ã –∑–∞–º–µ—Ä–∑—à–µ–≥–æ –æ–∑–µ—Ä–∞ (–¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å).\n",
        "- `is_slippery=True`: –ê–≥–µ–Ω—Ç **–Ω–µ –≤—Å–µ–≥–¥–∞ –º–æ–∂–µ—Ç –¥–≤–∏–≥–∞—Ç—å—Å—è –≤ –Ω–∞–º–µ—á–µ–Ω–Ω–æ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏** –∏–∑-–∑–∞ —Å–∫–æ–ª—å–∂–µ–Ω–∏—è –Ω–∞ –∑–∞–º–µ—Ä–∑—à–µ–º –æ–∑–µ—Ä–µ (—Å–ª—É—á–∞–π–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å)."
      ],
      "metadata": {
        "id": "fORJZzo2phaP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ê –ø–æ–∫–∞ –¥–∞–≤–∞–π—Ç–µ —Å–¥–µ–ª–∞–µ–º –≤—Å–µ –ø—Ä–æ—Å—Ç–æ —Å –∫–∞—Ä—Ç–æ–π 4—Ö4 –∏ –Ω–µ —Å–∫–æ–ª—å–∑–∫–æ–π"
      ],
      "metadata": {
        "id": "wcK7PO2bsZuk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NdoGHG-Jtl-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# –°–æ–∑–¥–∞–µ–º —Å—Ä–µ–¥—É FrozenLake-v1, –∏—Å–ø–æ–ª—å–∑—É—è –∫–∞—Ä—Ç—É 4x4 –∏ –≤–µ—Ä—Å–∏—é –±–µ–∑ —Å–∫–æ–ª—å–∂–µ–Ω–∏—è\n",
        "env = gym.make() # –í—ã–ø–æ–ª–Ω–∏—Ç–µ, –∏—Å–ø–æ–ª—å–∑—É—è –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã"
      ],
      "metadata": {
        "id": "ui04je9csh19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Solution"
      ],
      "metadata": {
        "id": "n5Mc6JS3tBYV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make(\"FrozenLake-v1\", map_name=\"4x4\", is_slippery=False)"
      ],
      "metadata": {
        "id": "addTFFc3tGe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "–í—ã –º–æ–∂–µ—Ç–µ —Å–æ–∑–¥–∞—Ç—å —Å–≤–æ—é —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—É—é –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫—É—é —Å–µ—Ç–∫—É —Å–ª–µ–¥—É—é—â–∏–º –æ–±—Ä–∞–∑–æ–º:\n",
        "\n",
        "```python\n",
        "desc=[\"SFFF\", \"FHFH\", \"FFFH\", \"HFFG\"]\n",
        "gym.make('FrozenLake-v1', desc=desc, is_slippery=True)\n",
        "```\n",
        "\n",
        "–Ω–æ –ø–æ–∫–∞ –º—ã –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å—Ä–µ–¥—É –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é."
      ],
      "metadata": {
        "id": "yE64B0PTtRh0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "sYsCv4swtHtV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### –î–∞–≤–∞–π—Ç–µ –ø–æ—Å–º–æ—Ç—Ä–∏–º, –∫–∞–∫ –≤—ã–≥–ª—è–¥–∏—Ç –æ–∫—Ä—É–∂–∞—é—â–∞—è —Å—Ä–µ–¥–∞:"
      ],
      "metadata": {
        "id": "I_zpGW5stlBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# –ú—ã —Å–æ–∑–¥–∞–µ–º –Ω–∞—à—É —Å—Ä–µ–¥—É —Å –ø–æ–º–æ—â—å—é gym.make(\"<name_of_the_environment>\")- `is_slippery=False`: –ê–≥–µ–Ω—Ç –≤—Å–µ–≥–¥–∞ –¥–≤–∏–∂–µ—Ç—Å—è –≤ –∑–∞–¥–∞–Ω–Ω–æ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏ –∏–∑-–∑–∞ –Ω–µ —Å–∫–æ–ª—å–∑–∫–æ–π –ø—Ä–∏—Ä–æ–¥—ã –∑–∞–º–µ—Ä–∑—à–µ–≥–æ –æ–∑–µ—Ä–∞ (–¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å).\n",
        "print(\"_____OBSERVATION SPACE_____ \\n\")\n",
        "print(\"Observation Space\", env.observation_space)\n",
        "print(\"Sample observation\", env.observation_space.sample()) # –ü–æ–ª—É—á–∞–µ–º —Å–ª—É—á–∞–π–Ω–æ–µ –Ω–∞–±–ª—é–¥–µ–Ω–∏–µ"
      ],
      "metadata": {
        "id": "isB96DS8tvZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ú—ã –≤–∏–¥–∏–º —Å –ø–æ–º–æ—â—å—é `Observation Space Shape Discrete(16)`, —á—Ç–æ –Ω–∞–±–ª—é–¥–µ–Ω–∏–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π —Ü–µ–ª–æ–µ —á–∏—Å–ª–æ, –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—â–µ–µ —Ç–µ–∫—É—â—É—é –ø–æ–∑–∏—Ü–∏—é –∞–≥–µ–Ω—Ç–∞ –∫–∞–∫ **current_row * nrows + current_col** (–≥–¥–µ –∏ —Å—Ç—Ä–æ–∫–∞, –∏ —Å—Ç–æ–ª–±–µ—Ü –Ω–∞—á–∏–Ω–∞—é—Ç—Å—è —Å 0).\n",
        "\n",
        "–ù–∞–ø—Ä–∏–º–µ—Ä, –ø–æ–ª–æ–∂–µ–Ω–∏–µ —Ü–µ–ª–∏ –Ω–∞ –∫–∞—Ä—Ç–µ 4x4 –º–æ–∂–µ—Ç –±—ã—Ç—å —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–æ —Å–ª–µ–¥—É—é—â–∏–º –æ–±—Ä–∞–∑–æ–º: 3 * 4 + 3 = 15. –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ–∑–º–æ–∂–Ω—ã—Ö –Ω–∞–±–ª—é–¥–µ–Ω–∏–π –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Ä–∞–∑–º–µ—Ä–∞ –∫–∞—Ä—Ç—ã. **–ù–∞–ø—Ä–∏–º–µ—Ä, –∫–∞—Ä—Ç–∞ 4x4 —Å–æ–¥–µ—Ä–∂–∏—Ç 16 –≤–æ–∑–º–æ–∂–Ω—ã—Ö –Ω–∞–±–ª—é–¥–µ–Ω–∏–π.**\n",
        "\n",
        "\n",
        "–ù–∞–ø—Ä–∏–º–µ—Ä, –≤–æ—Ç –∫–∞–∫ –≤—ã–≥–ª—è–¥–∏—Ç state = 0:\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/unit2/frozenlake.png\" alt=\"FrozenLake\">"
      ],
      "metadata": {
        "id": "jCUwJjd2t3KV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n _____ACTION SPACE_____ \\n\")\n",
        "print(\"Action Space Shape\", env.action_space.n)\n",
        "print(\"Action Space Sample\", env.action_space.sample()) # –í—ã–±–æ—Ä —Å–ª—É—á–∞–π–Ω–æ–≥–æ –¥–µ–π—Å—Ç–≤–∏—è"
      ],
      "metadata": {
        "id": "4rLQsellLrJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ü—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –¥–µ–π—Å—Ç–≤–∏–π (–Ω–∞–±–æ—Ä –≤–æ–∑–º–æ–∂–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–∂–µ—Ç –ø—Ä–µ–¥–ø—Ä–∏–Ω—è—Ç—å –∞–≥–µ–Ω—Ç) –¥–∏—Å–∫—Ä–µ—Ç–Ω–æ, –¥–æ—Å—Ç—É–ø–Ω–æ 4 –¥–µ–π—Å—Ç–≤–∏—è üéÆ :\n",
        "- 0: –ò–î–¢–ò –ù–ê–õ–ï–í–û\n",
        "- 1: –°–ü–£–°–ö–ê–¢–¨–°–Ø –í–ù–ò–ó\n",
        "- 2: –ò–î–¢–ò –ù–ê–ü–†–ê–í–û\n",
        "- 3: –ü–û–î–ù–ò–ú–ê–¢–¨–°–Ø –ù–ê–í–ï–†–•\n",
        "\n",
        "–§—É–Ω–∫—Ü–∏—è –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏—è üí∞ :\n",
        "- –î–æ—Å—Ç–∏–∂–µ–Ω–∏–µ —Ü–µ–ª–∏: +1\n",
        "- –ü–µ—Ä–µ—Ö–æ–¥ –Ω–∞ –∫–ª–µ—Ç–∫—É —Å —è–º–æ–π: 0\n",
        "- –ü–µ—Ä–µ—Ö–æ–¥ –Ω–∞ –∫–ª–µ—Ç–∫—É —Å–æ –ª—å–¥–æ–º: 0"
      ],
      "metadata": {
        "id": "K_uoaJAOMPn0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Q-table üóÑÔ∏è\n",
        "(üëÄ –®–∞–≥ 1 –ø—Å–µ–≤–¥–æ–∫–æ–¥–∞)\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit3/Q-learning-2.jpg\" alt=\"Q-Learning\" width=\"70%\"/>\n",
        "\n",
        "\n",
        "–ü—Ä–∏—à–ª–æ –≤—Ä–µ–º—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –Ω–∞—à—É Q-table! –ß—Ç–æ–±—ã –∑–Ω–∞—Ç—å, —Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫ (—Å–æ—Å—Ç–æ—è–Ω–∏–π) –∏ —Å—Ç–æ–ª–±—Ü–æ–≤ (–¥–µ–π—Å—Ç–≤–∏–π) –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å, –Ω–∞–º –Ω—É–∂–Ω–æ –∑–Ω–∞—Ç—å —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤ –¥–µ–π—Å—Ç–≤–∏–π –∏ –Ω–∞–±–ª—é–¥–µ–Ω–∏–π. –ú—ã —É–∂–µ –ø–æ–ª—É—á–∞–ª–∏ –∏—Ö –∑–Ω–∞—á–µ–Ω–∏—è —Ä–∞–Ω–µ–µ, –Ω–æ –º—ã —Ö–æ—Ç–∏–º –ø–æ–ª—É—á–∏—Ç—å –∏—Ö –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ, —á—Ç–æ–±—ã –Ω–∞—à –∞–ª–≥–æ—Ä–∏—Ç–º –±—ã–ª –æ–±–æ–±—â–µ–Ω –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Å—Ä–µ–¥. –¢—Ä–µ–Ω–∞–∂–µ—Ä–Ω—ã–π –∑–∞–ª –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–∞–º —Å–ø–æ—Å–æ–± —Å–¥–µ–ª–∞—Ç—å —ç—Ç–æ: `env.action_space.n` –∏ `env.observation_space.n`\n"
      ],
      "metadata": {
        "id": "b6_hcoTHN-NE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "state_space = \n",
        "print(\"There are \", state_space, \" possible states\")\n",
        "\n",
        "action_space = \n",
        "print(\"There are \", action_space, \" possible actions\")"
      ],
      "metadata": {
        "id": "wQryU-H7QC1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#–°–æ–∑–¥–∞–¥–∏–º –Ω–∞—à—É Q-table —Ä–∞–∑–º–µ—Ä–∞ (state_space, action_space) –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Ä–∞–≤–Ω—ã–º 0, –∏—Å–ø–æ–ª—å–∑—É—è np.zeros\n",
        "def initialize_q_table(state_space, action_space):\n",
        "  Qtable = \n",
        "  return Qtable"
      ],
      "metadata": {
        "id": "3Pzdcsd8QISz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Qtable_frozenlake = initialize_q_table(state_space, action_space)"
      ],
      "metadata": {
        "id": "XLwBmp4CQz4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### –†–µ—à–µ–Ω–∏–µ"
      ],
      "metadata": {
        "id": "_CfogTv-Rm2C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "state_space = env.observation_space.n\n",
        "print(\"–°—É—â–µ—Å—Ç–≤—É–µ—Ç \", state_space, \" –≤–æ–∑–º–æ–∂–Ω—ã—Ö —Å–æ—Å—Ç–æ—è–Ω–∏–π\")\n",
        "\n",
        "action_space = env.action_space.n\n",
        "print(\"–°—É—â–µ—Å—Ç–≤—É–µ—Ç \", action_space, \" –≤–æ–∑–º–æ–∂–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π\")"
      ],
      "metadata": {
        "id": "Z3WwqpB9RoAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# –°–æ–∑–¥–∞–¥–∏–º –Ω–∞—à—É Q-—Ç–∞–±–ª–∏—Ü—É —Ä–∞–∑–º–µ—Ä–∞ (state_space, action_space) –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Ä–∞–≤–Ω—ã–º 0, –∏—Å–ø–æ–ª—å–∑—É—è np.zeros\n",
        "def initialize_q_table(state_space, action_space):\n",
        "  Qtable = np.zeros((state_space, action_space))\n",
        "  return Qtable"
      ],
      "metadata": {
        "id": "NLj3qhK6Som7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Qtable_frozenlake = initialize_q_table(state_space, action_space)"
      ],
      "metadata": {
        "id": "8DeLiJxJTC7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ–ª–∏—Ç–∏–∫–∏ –∂–∞–¥–Ω–æ—Å—Ç–∏ ü§ñ\n",
        "–ü–æ–º–Ω–∏—Ç–µ, —á—Ç–æ —É –Ω–∞—Å –µ—Å—Ç—å –¥–≤–µ –ø–æ–ª–∏—Ç–∏–∫–∏, –ø–æ—Å–∫–æ–ª—å–∫—É Q-Learning - —ç—Ç–æ **–Ω–µ –ø–æ–ª–∏—Ç–∏—á–µ—Å–∫–∏–π** –∞–ª–≥–æ—Ä–∏—Ç–º. –≠—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –º—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º **–¥—Ä—É–≥—É—é –ø–æ–ª–∏—Ç–∏–∫—É –¥–ª—è –¥–µ–π—Å—Ç–≤–∏—è –∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–∏ –∑–Ω–∞—á–µ–Ω–∏—è**.\n",
        "\n",
        "- –≠–ø—Å–∏–ª–æ–Ω-–∂–∞–¥–Ω–∞—è –ø–æ–ª–∏—Ç–∏–∫–∞ (–¥–µ–π—Å—Ç–≤—É—é—â–∞—è –ø–æ–ª–∏—Ç–∏–∫–∞)\n",
        "- –ñ–∞–¥–Ω–∞—è-–ø–æ–ª–∏—Ç–∏–∫–∞ (–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–æ–ª–∏—Ç–∏–∫–∏)\n",
        "\n",
        "–ü–æ–ª–∏—Ç–∏–∫–∞ –∂–∞–¥–Ω–æ—Å—Ç–∏ —Ç–∞–∫–∂–µ –±—É–¥–µ—Ç –æ–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω–æ–π –ø–æ–ª–∏—Ç–∏–∫–æ–π, –∫–æ—Ç–æ—Ä—É—é –º—ã –ø–æ–ª—É—á–∏–º, –∫–æ–≥–¥–∞ –∞–≥–µ–Ω—Ç Q-learning –±—É–¥–µ—Ç –æ–±—É—á–µ–Ω. –ü–æ–ª–∏—Ç–∏–∫–∞ –∂–∞–¥–Ω–æ—Å—Ç–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –≤—ã–±–æ—Ä–∞ –¥–µ–π—Å—Ç–≤–∏—è –∏–∑ Q-—Ç–∞–±–ª–∏—Ü—ã.\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit3/off-on-4.jpg\" alt=\"Q-Learning\" width=\"70%\"/>\n"
      ],
      "metadata": {
        "id": "dMXL7vAYTDrq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def greedy_policy(Qtable, state):\n",
        "  # –≠–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏—è: –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –¥–µ–π—Å—Ç–≤–∏—è —Å –Ω–∞–∏–≤—ã—Å—à–∏–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ–º, –∑–Ω–∞—á–µ–Ω–∏–µ–º –¥–µ–π—Å—Ç–≤–∏—è\n",
        "  action = \n",
        "  \n",
        "  return action"
      ],
      "metadata": {
        "id": "qfza8GlxU46i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### –†–µ—à–µ–Ω–∏–µ"
      ],
      "metadata": {
        "id": "tt0RJXqBVD-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def greedy_policy(Qtable, state):\n",
        "  # Exploitation: take the action with the highest state, action value\n",
        "  action = np.argmax(Qtable[state][:])\n",
        "  \n",
        "  return action"
      ],
      "metadata": {
        "id": "m0EpOHGpVEzu"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ–ª–∏—Ç–∏–∫–∏ —ç–ø—Å–∏–ª–æ–Ω-–∂–∞–¥–Ω–æ—Å—Ç–∏ü§ñ\n",
        "\n",
        "–≠–ø—Å–∏–ª–æ–Ω-–∂–∞–¥–Ω–∞—è –ø–æ–ª–∏—Ç–∏–∫–∞ (Epsilon-greedy) - —ç—Ç–æ –ø–æ–ª–∏—Ç–∏–∫–∞ –æ–±—É—á–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä–∞—è —Ä–µ–≥—É–ª–∏—Ä—É–µ—Ç –∫–æ–º–ø—Ä–æ–º–∏—Å—Å –º–µ–∂–¥—É —Ä–∞–∑–≤–µ–¥–∫–æ–π –∏ —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏–µ–π.\n",
        "\n",
        "–ò–¥–µ—è —Å–æ—Å—Ç–æ–∏—Ç –≤ —Å–ª–µ–¥—É—é—â–µ–º:\n",
        "\n",
        "- –° –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é *(1 - …õ)* : **–º—ã –≤—ã–ø–æ–ª–Ω—è–µ–º —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏—é** (—Ç.–µ. –Ω–∞—à –∞–≥–µ–Ω—Ç –≤—ã–±–∏—Ä–∞–µ—Ç –¥–µ–π—Å—Ç–≤–∏–µ —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º –∑–Ω–∞—á–µ–Ω–∏–µ–º –ø–∞—Ä—ã —Å–æ—Å—Ç–æ—è–Ω–∏–µ-–¥–µ–π—Å—Ç–≤–∏–µ).\n",
        "\n",
        "- –° –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é *…õ* : –º—ã –ø—Ä–æ–≤–æ–¥–∏–º **–∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ** (–ø—Ä–æ–±—É–µ–º —Å–ª—É—á–∞–π–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ).\n",
        "\n",
        "–ò –ø–æ –º–µ—Ä–µ –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è –º—ã –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ **—É–º–µ–Ω—å—à–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ —ç–ø—Å–∏–ª–æ–Ω–∞, –ø–æ—Å–∫–æ–ª—å–∫—É –Ω–∞–º –±—É–¥–µ—Ç —Ç—Ä–µ–±–æ–≤–∞—Ç—å—Å—è –≤—Å–µ –º–µ–Ω—å—à–µ –∏ –º–µ–Ω—å—à–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π –∏ –≤—Å–µ –±–æ–ª—å—à–µ —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏–∏.**\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit3/Q-learning-4.jpg\" alt=\"Q-Learning\" width=\"70%\"/>"
      ],
      "metadata": {
        "id": "uqu5QyEoVO-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def epsilon_greedy_policy(Qtable, state, epsilon):\n",
        "  # –°–ª—É—á–∞–π–Ω—ã–º –æ–±—Ä–∞–∑–æ–º –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º —á–∏—Å–ª–æ –æ—Ç 0 –¥–æ 1\n",
        "  random_num = \n",
        "  # –µ—Å–ª–∏ random_num –±–æ–ª—å—à–µ, —á–µ–º —ç–ø—Å–∏–ª–æ–Ω –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏—è\n",
        "  if random_num > epsilon:\n",
        "    # –í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –¥–µ–π—Å—Ç–≤–∏–µ —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º –∑–Ω–∞—á–µ–Ω–∏–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏—è\n",
        "    # –¥–ª—è —ç—Ç–æ–≥–æ np.argmax –º–æ–∂–µ—Ç –±—ã—Ç—å –ø–æ–ª–µ–∑–µ–Ω\n",
        "    action = \n",
        "  # –µ—Å–ª–∏ –Ω–µ—Ç —Ç–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ\n",
        "  else:\n",
        "    action = # –°–æ–≤–µ—Ä—à–∞–µ—Ç—Å—è —Å–ª—É—á–∞–π–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ\n",
        "  \n",
        "  return action"
      ],
      "metadata": {
        "id": "5JKTDGIWaW9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### –†–µ—à–µ–Ω–∏–µ"
      ],
      "metadata": {
        "id": "NUvx7e4labeK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def epsilon_greedy_policy(Qtable, state, epsilon):\n",
        "  # Randomly generate a number between 0 and 1\n",
        "  random_int = random.uniform(0,1)\n",
        "  # if random_int > greater than epsilon --> exploitation\n",
        "  if random_int > epsilon:\n",
        "    # Take the action with the highest value given a state\n",
        "    # np.argmax can be useful here\n",
        "    action = greedy_policy(Qtable, state)\n",
        "  # else --> exploration\n",
        "  else:\n",
        "    action = env.action_space.sample()\n",
        "  \n",
        "  return action"
      ],
      "metadata": {
        "id": "ctgCGDpLaoUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ ‚öôÔ∏è\n",
        "–ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã, —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ–º, —è–≤–ª—è—é—Ç—Å—è –æ–¥–Ω–∏–º–∏ –∏–∑ –Ω–∞–∏–±–æ–ª–µ–µ –≤–∞–∂–Ω—ã—Ö.\n",
        "\n",
        "- –ù–∞–º –Ω—É–∂–Ω–æ —É–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –Ω–∞—à –∞–≥–µ–Ω—Ç **–∏—Å—Å–ª–µ–¥—É–µ—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞ —Å–æ—Å—Ç–æ—è–Ω–∏–π**, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å —Ö–æ—Ä–æ—à–µ–µ –ø—Ä–∏–±–ª–∏–∂–µ–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è. –ß—Ç–æ–±—ã —Å–¥–µ–ª–∞—Ç—å —ç—Ç–æ, –Ω–∞–º –Ω—É–∂–Ω–æ –∏–º–µ—Ç—å –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ —É–º–µ–Ω—å—à–µ–Ω–∏–µ —ç–ø—Å–∏–ª–æ–Ω–∞.\n",
        "- –ï—Å–ª–∏ –≤—ã —É–º–µ–Ω—å—à–∞–µ—Ç–µ —ç–ø—Å–∏–ª–æ–Ω —Å–ª–∏—à–∫–æ–º –±—ã—Å—Ç—Ä–æ, **–≤—ã —Ä–∏—Å–∫—É–µ—Ç–µ, —á—Ç–æ –≤–∞—à –∞–≥–µ–Ω—Ç –∑–∞—Å—Ç—Ä—è–Ω–µ—Ç**, –ø–æ—Å–∫–æ–ª—å–∫—É –≤–∞—à –∞–≥–µ–Ω—Ç –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–ª –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ —Å–æ—Å—Ç–æ—è–Ω–∏–π –∏, —Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ, –Ω–µ –º–æ–∂–µ—Ç —Ä–µ—à–∏—Ç—å –ø—Ä–æ–±–ª–µ–º—É."
      ],
      "metadata": {
        "id": "hPYZuKWCbrMj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏\n",
        "n_training_episodes = 10000  # –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö —ç–ø–∏–∑–æ–¥–æ–≤\n",
        "learning_rate = 0.7          # –°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è\n",
        "\n",
        "# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ—Ü–µ–Ω–∫–∏\n",
        "n_eval_episodes = 100        # –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ—Å—Ç–æ–≤—ã—Ö —ç–ø–∏–∑–æ–¥–æ–≤\n",
        "\n",
        "# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–∫—Ä—É–∂–∞—é—â–µ–π —Å—Ä–µ–¥—ã\n",
        "env_id = \"FrozenLake-v1\"     # –ù–∞–∑–≤–∞–Ω–∏–µ —Å—Ä–µ–¥—ã\n",
        "max_steps = 99               # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤ –∑–∞ —ç–ø–∏–∑–æ–¥\n",
        "gamma = 0.95                 # –°—Ç–∞–≤–∫–∞ –¥–∏—Å–∫–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏—è\n",
        "eval_seed = []               # –û—Ü–µ–Ω–æ—á–Ω–æ–µ —Å–µ–º—è –æ–∫—Ä—É–∂–∞—é—â–µ–π —Å—Ä–µ–¥—ã\n",
        "\n",
        "# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Ä–∞–∑–≤–µ–¥–∫–∏\n",
        "max_epsilon = 1.0             # –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Ä–∞–∑–≤–µ–¥–∫–∏ –Ω–∞ —Å—Ç–∞—Ä—Ç–µ\n",
        "min_epsilon = 0.05            # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Ä–∞–∑–≤–µ–¥–∫–∏\n",
        "decay_rate = 0.0005           # –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å –∑–∞—Ç—É—Ö–∞–Ω–∏—è –¥–ª—è –∑–∞–¥–∞—á–∏ —Ä–∞–∑–≤–µ–¥–∫–∏"
      ],
      "metadata": {
        "id": "6vk0kl_Ychyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## –°–æ–∑–¥–∞–Ω–∏–µ –º–µ—Ç–æ–¥–∞ (—Ü–∏–∫–ª–∞) –æ–±—É—á–µ–Ω–∏—è\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit3/Q-learning-2.jpg\" alt=\"Q-Learning\" width=\"70%\"/>\n",
        "\n",
        "–¶–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è –ø—Ä–æ—Ö–æ–¥–∏—Ç —Å–ª–µ–¥—É—é—â–∏–º –æ–±—Ä–∞–∑–æ–º:\n",
        "\n",
        "```\n",
        "–î–ª—è —ç–ø–∏–∑–æ–¥–∞ –≤ –æ–±—â–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö —ç–ø–∏–∑–æ–¥–æ–≤:\n",
        "\n",
        "–£–º–µ–Ω—å—à–∞–µ—Ç—Å—è —ç–ø—Å–∏–ª–æ–Ω (–ø–æ—Å–∫–æ–ª—å–∫—É –Ω–∞–º –Ω—É–∂–Ω–æ –≤—Å–µ –º–µ–Ω—å—à–µ –∏ –º–µ–Ω—å—à–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π)\n",
        "–ü–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏—Ç–µ –æ–∫—Ä—É–∂–∞—é—â—É—é —Å—Ä–µ–¥—É\n",
        "\n",
        " –î–ª—è —à–∞–≥–∞ –≤ –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã—Ö –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —à–∞–≥–∞—Ö:\n",
        "   –í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ –ø—Ä–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ –ø–æ–ª–∏—Ç–∏–∫–∏ epsilon greedy\n",
        "   –í—ã–ø–æ–ª–Ω–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ (a) –∏ –Ω–∞–±–ª—é–¥–∞–π—Ç–µ –∑–∞ —Å–æ—Å—Ç–æ—è–Ω–∏–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ (s') –∏     \n",
        "   –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏–µ–º (r)\n",
        "   –û–±–Ω–æ–≤–∏—Ç–µ –∑–Ω–∞—á–µ–Ω–∏–µ Q(s,a), –∏—Å–ø–æ–ª—å–∑—É—è —É—Ä–∞–≤–Ω–µ–Ω–∏–µ –ë–µ–ª–ª–º–∞–Ω–∞\n",
        "   Q(s,a) + lr [R(s,a) + gamma * max Q(s',a') - Q(s,a)]\n",
        "   –ï—Å–ª–∏ done, —ç–ø–∏–∑–æ–¥ –∑–∞–∫–æ–Ω—á–∏–≤–∞–µ—Ç—Å—è\n",
        "   –ù–∞—à–µ —Å–ª–µ–¥—É—é—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ - —ç—Ç–æ –Ω–æ–≤–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ\n",
        "```"
      ],
      "metadata": {
        "id": "UDnlQ4BcdeAa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(n_training_episodes, min_epsilon, max_epsilon, decay_rate, env, max_steps, Qtable):\n",
        "  for episode in tqdm(range(n_training_episodes)):\n",
        "    # –£–º–µ–Ω—å—à–µ–Ω–∏–µ —ç–ø—Å–∏–ª–æ–Ω (–ø–æ—Ç–æ–º—É —á—Ç–æ –Ω–∞–º –Ω—É–∂–Ω–æ –≤—Å–µ –º–µ–Ω—å—à–µ –∏ –º–µ–Ω—å—à–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π)\n",
        "    epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*episode)\n",
        "    # –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏—Ç–µ –æ–∫—Ä—É–∂–∞—é—â—É—é —Å—Ä–µ–¥—É\n",
        "    state = env.reset()\n",
        "    step = 0\n",
        "    done = False\n",
        "\n",
        "    # –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–µ\n",
        "    for step in range(max_steps):\n",
        "      # –í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ –ø—Ä–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ –≠–ø—Å–∏–ª–æ–Ω-–∂–∞–¥–Ω–æ–π –ø–æ–ª–∏—Ç–∏–∫–∏\n",
        "      action = \n",
        "\n",
        "      # –ü—Ä–∏–º–∏—Ç–µ –º–µ—Ä—ã –∏ —Å–æ–±–ª—é–¥–∞–π—Ç–µ Rt+1 –∏ St+1\n",
        "      # –í—ã–ø–æ–ª–Ω–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ (a) –∏ –Ω–∞–±–ª—é–¥–∞–π—Ç–µ –∑–∞ —Å–æ—Å—Ç–æ—è–Ω–∏–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ (s') –∏ –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏–µ–º (r)\n",
        "      new_state, reward, done, info = \n",
        "\n",
        "      # –û–±–Ω–æ–≤–∏—Ç–µ Q(s,a):= Q(s,a) + lr [R(s,a) + gamma * max Q(s',a') - Q(s,a)]\n",
        "      Qtable[state][action] = \n",
        "\n",
        "      # –ï—Å–ª–∏ done = True, —ç–ø–∏–∑–æ–¥ –∑–∞–∫–æ–Ω—á–∏–≤–∞–µ—Ç—Å—è\n",
        "      if done:\n",
        "        break\n",
        "      \n",
        "      # –ù–∞—à–µ —Å–ª–µ–¥—É—é—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ - —ç—Ç–æ –Ω–æ–≤–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ\n",
        "      state = new_state\n",
        "  return Qtable"
      ],
      "metadata": {
        "id": "mLXh6NwwfQ6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### –†–µ—à–µ–Ω–∏–µ"
      ],
      "metadata": {
        "id": "-Jlve30EgrKj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(n_training_episodes, min_epsilon, max_epsilon, decay_rate, env, max_steps, Qtable):\n",
        "  for episode in tqdm(range(n_training_episodes)):\n",
        "    # Reduce epsilon (because we need less and less exploration)\n",
        "    epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*episode)\n",
        "    # Reset the environment\n",
        "    state = env.reset()\n",
        "    step = 0\n",
        "    done = False\n",
        "\n",
        "    # repeat\n",
        "    for step in range(max_steps):\n",
        "      # Choose the action At using epsilon greedy policy\n",
        "      action = epsilon_greedy_policy(Qtable, state, epsilon)\n",
        "\n",
        "      # Take action At and observe Rt+1 and St+1\n",
        "      # Take the action (a) and observe the outcome state(s') and reward (r)\n",
        "      new_state, reward, done, info = env.step(action)\n",
        "\n",
        "      # Update Q(s,a):= Q(s,a) + lr [R(s,a) + gamma * max Q(s',a') - Q(s,a)]\n",
        "      Qtable[state][action] = Qtable[state][action] + learning_rate * (reward + gamma * np.max(Qtable[new_state]) - Qtable[state][action])   \n",
        "\n",
        "      # If done, finish the episode\n",
        "      if done:\n",
        "        break\n",
        "      \n",
        "      # Our next state is the new state\n",
        "      state = new_state\n",
        "  return Qtable"
      ],
      "metadata": {
        "id": "EIZKbUdDgvVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## –û–±—É—á–∏—Ç–µ –∞–≥–µ–Ω—Ç–∞ Q-Learning üèÉ"
      ],
      "metadata": {
        "id": "3YhfVctmhF1p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Qtable_frozenlake = train(n_training_episodes, min_epsilon, max_epsilon, decay_rate, env, max_steps, Qtable_frozenlake)"
      ],
      "metadata": {
        "id": "zvCYnD7ihUbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## –î–∞–≤–∞–π—Ç–µ –ø–æ—Å–º–æ—Ç—Ä–∏–º, –∫–∞–∫ —Ç–µ–ø–µ—Ä—å –≤—ã–≥–ª—è–¥–∏—Ç –Ω–∞—à–∞ —Ç–∞–±–ª–∏—Ü–∞ Q-Learning üëÄ"
      ],
      "metadata": {
        "id": "7Kqn_BZHheJD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Qtable_frozenlake"
      ],
      "metadata": {
        "id": "tVXO3yEuhi1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## –ú–µ—Ç–æ–¥ –æ—Ü–µ–Ω–∫–∏ üìù\n",
        "\n",
        "- –ú—ã –æ–ø—Ä–µ–¥–µ–ª–∏–ª–∏ –º–µ—Ç–æ–¥ –æ—Ü–µ–Ω–∫–∏, –∫–æ—Ç–æ—Ä—ã–π –º—ã —Å–æ–±–∏—Ä–∞–µ–º—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–∞—à–µ–≥–æ –∞–≥–µ–Ω—Ç–∞ Q-Learning."
      ],
      "metadata": {
        "id": "C_SBV9QUhl0C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_agent(env, max_steps, n_eval_episodes, Q, seed):\n",
        "  \"\"\"\n",
        "  –û—Ü–µ–Ω–∏—Ç–µ –∞–≥–µ–Ω—Ç–∞ –¥–ª—è `n_eval_episodes` —ç–ø–∏–∑–æ–¥–æ–≤ –∏ –≤–µ—Ä–Ω–∏—Ç–µ —Å—Ä–µ–¥–Ω–µ–µ –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏–µ –∏ std –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏—è.\n",
        "  :–ø–∞—Ä–∞–º–µ—Ç—Ä env: –°—Ä–µ–¥–∞ –æ—Ü–µ–Ω–∫–∏\n",
        "  :–ø–∞—Ä–∞–º–µ—Ç—Ä n_eval_episodes: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–∏–∑–æ–¥–æ–≤ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∞–≥–µ–Ω—Ç–∞\n",
        "  :–ü–∞—Ä–∞–º–µ—Ç—Ä Q: Q-—Ç–∞–±–ª–∏—Ü–∞\n",
        "  :–ø–∞—Ä–∞–º–µ—Ç—Ä seed: –û—Ü–µ–Ω–æ—á–Ω—ã–π –Ω–∞—á–∞–ª—å–Ω—ã–π –º–∞—Å—Å–∏–≤ (–¥–ª—è taxi-v3)\n",
        "  \"\"\"\n",
        "  episode_rewards = []\n",
        "  for episode in tqdm(range(n_eval_episodes)):\n",
        "    if seed:\n",
        "      state = env.reset(seed=seed[episode])\n",
        "    else:\n",
        "      state = env.reset()\n",
        "    step = 0\n",
        "    done = False\n",
        "    total_rewards_ep = 0\n",
        "    \n",
        "    for step in range(max_steps):\n",
        "      # –í—ã–ø–æ–ª–Ω–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ, –∫–æ—Ç–æ—Ä–æ–µ –∏–º–µ–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –æ–∂–∏–¥–∞–µ–º—É—é –±—É–¥—É—â—É—é –Ω–∞–≥—Ä–∞–¥—É —Å —É—á–µ—Ç–æ–º —ç—Ç–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è\n",
        "      action = greedy_policy(Q, state)\n",
        "      new_state, reward, done, info = env.step(action)\n",
        "      total_rewards_ep += reward\n",
        "        \n",
        "      if done:\n",
        "        break\n",
        "      state = new_state\n",
        "    episode_rewards.append(total_rewards_ep)\n",
        "  mean_reward = np.mean(episode_rewards)\n",
        "  std_reward = np.std(episode_rewards)\n",
        "\n",
        "  return mean_reward, std_reward"
      ],
      "metadata": {
        "id": "Zy8xZelrhvva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## –û—Ü–µ–Ω–∏—Ç–µ –Ω–∞—à–µ–≥–æ Q-Learning –∞–≥–µ–Ω—Ç–∞ üìà\n",
        "\n",
        "- –û–±—ã—á–Ω–æ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Å—Ä–µ–¥–Ω–µ–µ –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏–µ –≤ —Ä–∞–∑–º–µ—Ä–µ 1,0\n",
        "- –°—Ä–µ–¥–∞ **–æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –ø—Ä–æ—Å—Ç–∞**, –ø–æ—Å–∫–æ–ª—å–∫—É –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ —Å–æ—Å—Ç–æ—è–Ω–∏–π –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –º–∞–ª–æ (16). –î–ª—è —É—Å–ª–æ–∂–Ω–µ–Ω–∏—è –º–æ–∂–Ω–æ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å [–∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ —Å–∫–æ–ª—å–∑–∫—É—é –≤–µ—Ä—Å–∏—é](https://www.gymlibrary.dev/environments/toy_text/frozen_lake/), —á—Ç–æ –≤–≤–æ–¥–∏—Ç —Å—Ç–æ—Ö–∞—Å—Ç–∏—á–Ω–æ—Å—Ç—å, –¥–µ–ª–∞—è –æ–∫—Ä—É–∂–∞—é—â—É—é —Å—Ä–µ–¥—É –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω–æ–π."
      ],
      "metadata": {
        "id": "KGdgZU7UjKzJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# –û—Ü–µ–Ω–∫–∞ –∞–≥–µ–Ω—Ç–∞\n",
        "mean_reward, std_reward = evaluate_agent(env, max_steps, n_eval_episodes, Qtable_frozenlake, eval_seed)\n",
        "print(f\"Mean_reward={mean_reward:.2f} +/- {std_reward:.2f}\")"
      ],
      "metadata": {
        "id": "qnujKBTFkBkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## –û–ø—É–±–ª–∏–∫–∞—Ü–∏—è –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ Hub üî•\n",
        "\n",
        "–¢–µ–ø–µ—Ä—å, –ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è, **–º—ã –º–æ–∂–µ–º –æ–ø—É–±–ª–∏–∫–æ–≤–∞—Ç—å –Ω–∞—à—É –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –Ω–∞ Hub ü§ó —Å –ø–æ–º–æ—â—å—é –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ –∫–æ–¥–∞**.\n",
        "\n",
        "–í–æ—Ç –ø—Ä–∏–º–µ—Ä –º–æ–¥–µ–ª—å–Ω–æ–π –∫–∞—Ä—Ç–æ—á–∫–∏:\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/unit2/modelcard.png\" alt=\"Model card\" width=\"70%\"/>\n"
      ],
      "metadata": {
        "id": "N7X1Sq35kMXF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ü–æ–¥ –∫–∞–ø–æ—Ç–æ–º –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ç–æ—Ä (Hub) –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ git (–Ω–µ –≤–æ–ª–Ω—É–π—Ç–µ—Å—å, –µ—Å–ª–∏ –≤—ã –Ω–µ –∑–Ω–∞–µ—Ç–µ, —á—Ç–æ —Ç–∞–∫–æ–µ git), —á—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –≤—ã –º–æ–∂–µ—Ç–µ –æ–±–Ω–æ–≤–ª—è—Ç—å –º–æ–¥–µ–ª—å –Ω–æ–≤—ã–º–∏ –≤–µ—Ä—Å–∏—è–º–∏ –ø–æ –º–µ—Ä–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ –∏ —É–ª—É—á—à–µ–Ω–∏—è –≤–∞—à–µ–≥–æ –∞–≥–µ–Ω—Ç–∞."
      ],
      "metadata": {
        "id": "c0KjlS8XkyFq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### –ù–µ –∏–∑–º–µ–Ω—è–π—Ç–µ —ç—Ç–æ—Ç –∫–æ–¥"
      ],
      "metadata": {
        "id": "AHBOGRoqk94L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import HfApi, snapshot_download\n",
        "from huggingface_hub.repocard import metadata_eval_result, metadata_save\n",
        "\n",
        "from pathlib import Path\n",
        "import datetime\n",
        "import json"
      ],
      "metadata": {
        "id": "Z0-MZvwjlF51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def record_video(env, Qtable, out_directory, fps=1):\n",
        "  \"\"\"\n",
        "  Generate a replay video of the agent\n",
        "  :param env\n",
        "  :param Qtable: Qtable of our agent\n",
        "  :param out_directory\n",
        "  :param fps: how many frame per seconds (with taxi-v3 and frozenlake-v1 we use 1)\n",
        "  \"\"\"\n",
        "  images = []  \n",
        "  done = False\n",
        "  state = env.reset(seed=random.randint(0,500))\n",
        "  img = env.render(mode='rgb_array')\n",
        "  images.append(img)\n",
        "  while not done:\n",
        "    # Take the action (index) that have the maximum expected future reward given that state\n",
        "    action = np.argmax(Qtable[state][:])\n",
        "    state, reward, done, info = env.step(action) # We directly put next_state = state for recording logic\n",
        "    img = env.render(mode='rgb_array')\n",
        "    images.append(img)\n",
        "  imageio.mimsave(out_directory, [np.array(img) for i, img in enumerate(images)], fps=fps)"
      ],
      "metadata": {
        "id": "15J8_ue7lJEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def push_to_hub(\n",
        "    repo_id, model, env, video_fps=1, local_repo_path=\"hub\"\n",
        "):\n",
        "    \"\"\"\n",
        "    Evaluate, Generate a video and Upload a model to Hugging Face Hub.\n",
        "    This method does the complete pipeline:\n",
        "    - It evaluates the model\n",
        "    - It generates the model card\n",
        "    - It generates a replay video of the agent\n",
        "    - It pushes everything to the Hub\n",
        "\n",
        "    :param repo_id: repo_id: id of the model repository from the Hugging Face Hub\n",
        "    :param env\n",
        "    :param video_fps: how many frame per seconds to record our video replay \n",
        "    (with taxi-v3 and frozenlake-v1 we use 1)\n",
        "    :param local_repo_path: where the local repository is\n",
        "    \"\"\"\n",
        "    _, repo_name = repo_id.split(\"/\")\n",
        "\n",
        "    eval_env = env\n",
        "    api = HfApi()\n",
        "\n",
        "    # Step 1: Create the repo\n",
        "    repo_url = api.create_repo(\n",
        "        repo_id=repo_id,\n",
        "        exist_ok=True,\n",
        "    )\n",
        "\n",
        "    # Step 2: Download files\n",
        "    repo_local_path = Path(snapshot_download(repo_id=repo_id))\n",
        "\n",
        "    # Step 3: Save the model\n",
        "    if env.spec.kwargs.get(\"map_name\"):\n",
        "        model[\"map_name\"] = env.spec.kwargs.get(\"map_name\")\n",
        "        if env.spec.kwargs.get(\"is_slippery\", \"\") == False:\n",
        "            model[\"slippery\"] = False\n",
        "\n",
        "    # Pickle the model\n",
        "    with open((repo_local_path) / \"q-learning.pkl\", \"wb\") as f:\n",
        "        pickle.dump(model, f)\n",
        "\n",
        "    # Step 4: Evaluate the model and build JSON with evaluation metrics\n",
        "    mean_reward, std_reward = evaluate_agent(\n",
        "        eval_env, model[\"max_steps\"], model[\"n_eval_episodes\"], model[\"qtable\"], model[\"eval_seed\"]\n",
        "    )\n",
        "\n",
        "    evaluate_data = {\n",
        "        \"env_id\": model[\"env_id\"],\n",
        "        \"mean_reward\": mean_reward,\n",
        "        \"n_eval_episodes\": model[\"n_eval_episodes\"],\n",
        "        \"eval_datetime\": datetime.datetime.now().isoformat()\n",
        "    }\n",
        "\n",
        "    # Write a JSON file called \"results.json\" that will contain the\n",
        "    # evaluation results\n",
        "    with open(repo_local_path / \"results.json\", \"w\") as outfile:\n",
        "        json.dump(evaluate_data, outfile)\n",
        "\n",
        "    # Step 5: Create the model card\n",
        "    env_name = model[\"env_id\"]\n",
        "    if env.spec.kwargs.get(\"map_name\"):\n",
        "        env_name += \"-\" + env.spec.kwargs.get(\"map_name\")\n",
        "\n",
        "    if env.spec.kwargs.get(\"is_slippery\", \"\") == False:\n",
        "        env_name += \"-\" + \"no_slippery\"\n",
        "\n",
        "    metadata = {}\n",
        "    metadata[\"tags\"] = [env_name, \"q-learning\", \"reinforcement-learning\", \"custom-implementation\"]\n",
        "\n",
        "    # Add metrics\n",
        "    eval = metadata_eval_result(\n",
        "        model_pretty_name=repo_name,\n",
        "        task_pretty_name=\"reinforcement-learning\",\n",
        "        task_id=\"reinforcement-learning\",\n",
        "        metrics_pretty_name=\"mean_reward\",\n",
        "        metrics_id=\"mean_reward\",\n",
        "        metrics_value=f\"{mean_reward:.2f} +/- {std_reward:.2f}\",\n",
        "        dataset_pretty_name=env_name,\n",
        "        dataset_id=env_name,\n",
        "    )\n",
        "\n",
        "    # Merges both dictionaries\n",
        "    metadata = {**metadata, **eval}\n",
        "\n",
        "    model_card = f\"\"\"\n",
        "  # **Q-Learning** Agent playing1 **{env_id}**\n",
        "  This is a trained model of a **Q-Learning** agent playing **{env_id}** .\n",
        "\n",
        "  ## Usage\n",
        "\n",
        "  ```python\n",
        "  \n",
        "  model = load_from_hub(repo_id=\"{repo_id}\", filename=\"q-learning.pkl\")\n",
        "\n",
        "  # Don't forget to check if you need to add additional attributes (is_slippery=False etc)\n",
        "  env = gym.make(model[\"env_id\"])\n",
        "  ```\n",
        "  \"\"\"\n",
        "\n",
        "    evaluate_agent(env, model[\"max_steps\"], model[\"n_eval_episodes\"], model[\"qtable\"], model[\"eval_seed\"])\n",
        "  \n",
        "    readme_path = repo_local_path / \"README.md\"\n",
        "    readme = \"\"\n",
        "    print(readme_path.exists())\n",
        "    if readme_path.exists():\n",
        "        with readme_path.open(\"r\", encoding=\"utf8\") as f:\n",
        "            readme = f.read()\n",
        "    else:\n",
        "        readme = model_card\n",
        "\n",
        "    with readme_path.open(\"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(readme)\n",
        "\n",
        "    # Save our metrics to Readme metadata\n",
        "    metadata_save(readme_path, metadata)\n",
        "\n",
        "    # Step 6: Record a video\n",
        "    video_path = repo_local_path / \"replay.mp4\"\n",
        "    record_video(env, model[\"qtable\"], video_path, video_fps)\n",
        "\n",
        "    # Step 7. Push everything to the Hub\n",
        "    api.upload_folder(\n",
        "        repo_id=repo_id,\n",
        "        folder_path=repo_local_path,\n",
        "        path_in_repo=\".\",\n",
        "    )\n",
        "\n",
        "    print(\"Your model is pushed to the Hub. You can view your model here: \", repo_url)"
      ],
      "metadata": {
        "id": "-eLrQyznlMp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### .\n",
        "\n",
        "–ò—Å–ø–æ–ª—å–∑—É—è `push_to_hub` **, –≤—ã –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç–µ, –∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç–µ –ø–æ–≤—Ç–æ—Ä, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç–µ –∫–∞—Ä—Ç–æ—á–∫—É –º–æ–¥–µ–ª–∏ –≤–∞—à–µ–≥–æ –∞–≥–µ–Ω—Ç–∞ –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç–µ –µ–µ –Ω–∞ Hub**.\n",
        "\n",
        "–¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º:\n",
        "- –í—ã –º–æ–∂–µ—Ç–µ **–ø—Ä–æ–¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å —Å–≤–æ—é —Ä–∞–±–æ—Ç—É** üî•\n",
        "- –í—ã –º–æ–∂–µ—Ç–µ **–≤–∏–∑—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å, –∫–∞–∫ –≤–∞—à –∞–≥–µ–Ω—Ç –∏–≥—Ä–∞–µ—Ç** üëÄ\n",
        "- –í—ã –º–æ–∂–µ—Ç–µ **–ø–æ–¥–µ–ª–∏—Ç—å—Å—è —Å —Å–æ–æ–±—â–µ—Å—Ç–≤–æ–º –∞–≥–µ–Ω—Ç–æ–º, –∫–æ—Ç–æ—Ä—ã–º –º–æ–≥—É—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –¥—Ä—É–≥–∏–µ** üíæ\n",
        "- –í—ã –º–æ–∂–µ—Ç–µ **–ø–æ–ª—É—á–∏—Ç—å –¥–æ—Å—Ç—É–ø –∫ —Ç–∞–±–ª–∏—Ü–µ –ª–∏–¥–µ—Ä–æ–≤ üèÜ , —á—Ç–æ–±—ã —É–≤–∏–¥–µ—Ç—å, –Ω–∞—Å–∫–æ–ª—å–∫–æ —Ö–æ—Ä–æ—à–æ —Ä–∞–±–æ—Ç–∞–µ—Ç –≤–∞—à –∞–≥–µ–Ω—Ç –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å –≤–∞—à–∏–º–∏ –æ–¥–Ω–æ–∫–ª–∞—Å—Å–Ω–∏–∫–∞–º–∏** üëâ  https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard"
      ],
      "metadata": {
        "id": "SLevdfRIlRP1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ß—Ç–æ–±—ã –∏–º–µ—Ç—å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –ø–æ–¥–µ–ª–∏—Ç—å—Å—è —Å–≤–æ–µ–π –º–æ–¥–µ–ª—å—é —Å —Å–æ–æ–±—â–µ—Å—Ç–≤–æ–º, –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –≤—ã–ø–æ–ª–Ω–∏—Ç—å –µ—â–µ —Ç—Ä–∏ —à–∞–≥–∞:\n",
        "\n",
        "1Ô∏è‚É£ (–µ—Å–ª–∏ —ç—Ç–æ –µ—â–µ –Ω–µ —Å–¥–µ–ª–∞–Ω–æ) —Å–æ–∑–¥–∞–π—Ç–µ —É—á–µ—Ç–Ω—É—é –∑–∞–ø–∏—Å—å –¥–ª—è HF ‚û° https://huggingface.co/join\n",
        "\n",
        "2Ô∏è‚É£ –í–æ–π–¥–∏—Ç–µ –≤ —Å–∏—Å—Ç–µ–º—É, –∞ –∑–∞—Ç–µ–º –≤–∞–º –Ω—É–∂–Ω–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å–≤–æ–π —Ç–æ–∫–µ–Ω –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å –≤–µ–±-—Å–∞–π—Ç–∞ Hugging Face.\n",
        "- –°–æ–∑–¥–∞–π—Ç–µ –Ω–æ–≤—ã–π —Ç–æ–∫–µ–Ω (https://huggingface.co/settings/tokens ) **—Å —Ä–æ–ª—å—é –∑–∞–ø–∏—Å–∏**\n",
        "\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/create-token.jpg\" alt=\"Create HF Token\" width=\"30%\">\n"
      ],
      "metadata": {
        "id": "Ko_uE1O3mDyq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "hm144EUAmkyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ï—Å–ª–∏ –≤—ã –Ω–µ —Ö–æ—Ç–∏—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∑–∞–ø–∏—Å–Ω—É—é –∫–Ω–∏–∂–∫—É Google Colabora Jupyter, –≤–∞–º –Ω—É–∂–Ω–æ –≤–º–µ—Å—Ç–æ —ç—Ç–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —ç—Ç—É –∫–æ–º–∞–Ω–¥—É: `huggingface-cli login` (–∏–ª–∏ `login`)"
      ],
      "metadata": {
        "id": "cRkAe_P4mq6c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3Ô∏è‚É£ –¢–µ–ø–µ—Ä—å –º—ã –≥–æ—Ç–æ–≤—ã –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –Ω–∞—à–µ–≥–æ –æ–±—É—á–µ–Ω–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞ –≤ \"–ö–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ç–æ—Ä\", –∏—Å–ø–æ–ª—å–∑—É—è —Ñ—É–Ω–∫—Ü–∏—é \"push_to_hub()\"\n",
        "\n",
        "- –î–∞–≤–∞–π—Ç–µ —Å–æ–∑–¥–∞–¥–∏–º **—Å–ª–æ–≤–∞—Ä—å –º–æ–¥–µ–ª–∏, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ Q_table**."
      ],
      "metadata": {
        "id": "PNb0B53im8cT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = {\n",
        "    \"env_id\": env_id,\n",
        "    \"max_steps\": max_steps,\n",
        "    \"n_training_episodes\": n_training_episodes,\n",
        "    \"n_eval_episodes\": n_eval_episodes,\n",
        "    \"eval_seed\": eval_seed,\n",
        "\n",
        "    \"learning_rate\": learning_rate,\n",
        "    \"gamma\": gamma,\n",
        "\n",
        "    \"max_epsilon\": max_epsilon,\n",
        "    \"min_epsilon\": min_epsilon,\n",
        "    \"decay_rate\": decay_rate,\n",
        "\n",
        "    \"qtable\": Qtable_frozenlake\n",
        "}"
      ],
      "metadata": {
        "id": "nO1r_Hm0nIXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "–î–∞–≤–∞–π—Ç–µ –∑–∞–ø–æ–ª–Ω–∏–º —Ñ—É–Ω–∫—Ü–∏—é `push_to_hub`:\n",
        "\n",
        "- `repo_id`: –∏–º—è —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è Hugging Face Hub, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω/–æ–±–Ω–æ–≤–ª–µ–Ω `\n",
        "(repo_id = {–∏–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è}/{–∏–º—è_–ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ–ª—è})`\n",
        "üí° –•–æ—Ä–æ—à–∏–π `repo_id` - —ç—Ç–æ `{username}/q-{env_id}`\n",
        "- `–º–æ–¥–µ–ª—å`: –Ω–∞—à –º–æ–¥–µ–ª—å–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ —Ç–∞–±–ª–∏—Ü—É.\n",
        "- `env`: –æ–∫—Ä—É–∂–∞—é—â–∞—è —Å—Ä–µ–¥–∞.\n",
        "- `commit_message`: —Å–æ–æ–±—â–µ–Ω–∏–µ –æ —Ñ–∏–∫—Å–∞—Ü–∏–∏"
      ],
      "metadata": {
        "id": "5RPNrqVSnLkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "T12mV68Nnami"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "username = \"\" # FILL THIS\n",
        "repo_name = \"q-FrozenLake-v1-4x4-noSlippery\"\n",
        "push_to_hub(\n",
        "    repo_id=f\"{username}/{repo_name}\",\n",
        "    model=model,\n",
        "    env=env)"
      ],
      "metadata": {
        "id": "zg0yg3uMnbVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ü–æ–∑–¥—Ä–∞–≤–ª—è–µ–º ü•≥ –í—ã —Ç–æ–ª—å–∫–æ —á—Ç–æ –≤–Ω–µ–¥—Ä–∏–ª–∏ —Å –Ω—É–ª—è, –æ–±—É—á–∏–ª–∏ –∏ –∑–∞–≥—Ä—É–∑–∏–ª–∏ —Å–≤–æ–π –ø–µ—Ä–≤—ã–π –æ–±—É—á–∞—é—â–∏–π –∞–≥–µ–Ω—Ç —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º.\n",
        "FrozenLake-v1 no_slippery - –æ—á–µ–Ω—å –ø—Ä–æ—Å—Ç–∞—è —Å—Ä–µ–¥–∞, –¥–∞–≤–∞–π—Ç–µ –ø–æ–ø—Ä–æ–±—É–µ–º –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—É—é üî• ."
      ],
      "metadata": {
        "id": "hzpfANp0nj4x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# –ß–∞—Å—Ç—å 2: Taxi-v3 üöñ\n",
        "\n",
        "## –°–æ–∑–¥–∞—Ç—å –∏ –ø–æ–Ω—è—Ç—å [Taxi-v3 üöï](https://www.gymlibrary.dev/environments/toy_text/taxi/)\n",
        "---\n",
        "\n",
        "üí° –•–æ—Ä–æ—à–µ–π –ø—Ä–∏–≤—ã—á–∫–æ–π, –∫–æ–≥–¥–∞ –≤—ã –Ω–∞—á–∏–Ω–∞–µ—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å—Ä–µ–¥—É, —è–≤–ª—è–µ—Ç—Å—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –µ–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏\n",
        "\n",
        "üëâ https://www.gymlibrary.dev/environments/toy_text/taxi/\n",
        "\n",
        "---\n",
        "\n",
        "–í \"–¢–∞–∫—Å–∏-v3\" üöï –µ—Å—Ç—å —á–µ—Ç—ã—Ä–µ –æ–±–æ–∑–Ω–∞—á–µ–Ω–Ω—ã—Ö –º–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏—è –≤ —Å–µ—Ç–æ—á–Ω–æ–º –º–∏—Ä–µ, –æ–±–æ–∑–Ω–∞—á–µ–Ω–Ω—ã–µ R(ed), G(reen), Y(ellow) –∏ B(lue).\n",
        "\n",
        "–ö–æ–≥–¥–∞ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —ç–ø–∏–∑–æ–¥, ** —Ç–∞–∫—Å–∏ —Ç—Ä–æ–≥–∞–µ—Ç—Å—è —Å –º–µ—Å—Ç–∞ –≤ —Å–ª—É—á–∞–π–Ω–æ–º –∫–≤–∞–¥—Ä–∞—Ç–µ**, –∞ –ø–∞—Å—Å–∞–∂–∏—Ä –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —Å–ª—É—á–∞–π–Ω–æ–º –º–µ—Å—Ç–µ. –¢–∞–∫—Å–∏ –ø–æ–¥—ä–µ–∑–∂–∞–µ—Ç –∫ –º–µ—Å—Ç—É –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏—è –ø–∞—Å—Å–∞–∂–∏—Ä–∞, ** –∑–∞–±–∏—Ä–∞–µ—Ç –ø–∞—Å—Å–∞–∂–∏—Ä–∞**, –¥–æ–µ–∑–∂–∞–µ—Ç –¥–æ –º–µ—Å—Ç–∞ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è –ø–∞—Å—Å–∞–∂–∏—Ä–∞ (–¥—Ä—É–≥–æ–≥–æ –∏–∑ —á–µ—Ç—ã—Ä–µ—Ö —É–∫–∞–∑–∞–Ω–Ω—ã—Ö –º–µ—Å—Ç), –∞ –∑–∞—Ç–µ–º ** –≤—ã—Å–∞–∂–∏–≤–∞–µ—Ç –ø–∞—Å—Å–∞–∂–∏—Ä–∞**. –ö–∞–∫ —Ç–æ–ª—å–∫–æ –ø–∞—Å—Å–∞–∂–∏—Ä –≤—ã—Å–∞–∂–∏–≤–∞–µ—Ç—Å—è, —ç–ø–∏–∑–æ–¥ –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è.\n",
        "\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/unit2/taxi.png\" alt=\"Taxi\" width=\"50%\">\n"
      ],
      "metadata": {
        "id": "p6JAarg0nndS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make(\"Taxi-v3\")"
      ],
      "metadata": {
        "id": "gCWF59dgoX9E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}