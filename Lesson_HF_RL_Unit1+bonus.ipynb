{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNMktOl2G0tXeo/94cECt0L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fb97f50548214899a1f76e7c9a5e162e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a859c3c184df4e1db7ef0dd1099ba7cf",
              "IPY_MODEL_84d1e0688de34a409b143fc8dafcd354",
              "IPY_MODEL_730c6dd744e54685b5c3d791c0323460",
              "IPY_MODEL_cbf6b9f7525647dcad31e9a43584ae33",
              "IPY_MODEL_f34899b25b4b45b3bea9fc96e85c71da"
            ],
            "layout": "IPY_MODEL_e6e8fbf9c5fe4f879b2edd9b2745be8b"
          }
        },
        "a859c3c184df4e1db7ef0dd1099ba7cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01d3fba2895d4ebdbfba95c4b71c2cce",
            "placeholder": "​",
            "style": "IPY_MODEL_a6f39b55abd04923a48c3edee4531a89",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "84d1e0688de34a409b143fc8dafcd354": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_ebaeeb3aea0b47bc8d517bce004c2afe",
            "placeholder": "​",
            "style": "IPY_MODEL_982154a224ee441db01676eda6df3ec7",
            "value": ""
          }
        },
        "730c6dd744e54685b5c3d791c0323460": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_88f9f2038c41457cbba82bb7170dd8d9",
            "style": "IPY_MODEL_c313c022302f4947b4e83aa152952f64",
            "value": true
          }
        },
        "cbf6b9f7525647dcad31e9a43584ae33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_185f2fc502004bb98379b808f64c2b50",
            "style": "IPY_MODEL_38d67d4fc5ec47abad0f0e2c65c806c9",
            "tooltip": ""
          }
        },
        "f34899b25b4b45b3bea9fc96e85c71da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_480fd15273f4443d9eb6338cf4378de2",
            "placeholder": "​",
            "style": "IPY_MODEL_85a4f7480de84fe89efe61c9fe0c9ab6",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "e6e8fbf9c5fe4f879b2edd9b2745be8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "01d3fba2895d4ebdbfba95c4b71c2cce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6f39b55abd04923a48c3edee4531a89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ebaeeb3aea0b47bc8d517bce004c2afe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "982154a224ee441db01676eda6df3ec7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88f9f2038c41457cbba82bb7170dd8d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c313c022302f4947b4e83aa152952f64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "185f2fc502004bb98379b808f64c2b50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38d67d4fc5ec47abad0f0e2c65c806c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "480fd15273f4443d9eb6338cf4378de2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85a4f7480de84fe89efe61c9fe0c9ab6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Art-phys/Lesson_HF_LR_Unit1/blob/main/Lesson_HF_RL_Unit1%2Bbonus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ССЫЛКА НА ОРИГИНАЛ:\n",
        "\n",
        "https://colab.research.google.com/github/huggingface/deep-rl-class/blob/master/notebooks/bonus-unit1/bonus-unit1.ipynb\n",
        "\n",
        "@huggingface\n",
        "\n",
        "@simoninithomas"
      ],
      "metadata": {
        "id": "SGL_1R5LSr-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Бонусный блок 1: Давайте научим собаку Хагги 🐶 приносить палку"
      ],
      "metadata": {
        "id": "XnZg0hzGS56t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit2/thumbnail.png\" alt=\"Bonus Unit 1Thumbnail\" width=\"50%\">\n",
        "\n",
        "В этой тетради мы закрепим то, что узнали в первом разделе, **научив собаку Хагги приносить палку, а затем играть с ней прямо в вашем браузере**\n",
        "\n",
        "⬇️ Вот пример того, чего **вы достигнете в конце блока.** ⬇️ (запустите ▶ , чтобы увидеть)"
      ],
      "metadata": {
        "id": "M76ymwB8TFU1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ErCVfQsczkAU"
      },
      "outputs": [],
      "source": [
        "%%html\n",
        "<video controls autoplay><source src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/unit-bonus1/huggy.mp4\" type=\"video/mp4\"></video>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Окружающая среда 🎮\n",
        "\n",
        "- Собака Хагги, окружающая среда, созданная [Thomas Simonini](https://twitter.com/ThomasSimonini) основанная на [Puppo The Corgi](https://blog.unity.com/technology/puppo-the-corgi-cuteness-overload-with-the-unity-ml-agents-toolkit)\n",
        "\n",
        "### Используемая библиотека 📚\n",
        "\n",
        "- [MLAgents (Hugging Face version)](https://github.com/huggingface/ml-agents)"
      ],
      "metadata": {
        "id": "n5JQCzK4VK5M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Цели этого блокнота 🏆\n",
        "\n",
        "В конце блокнота вы:\n",
        "\n",
        "- Разберетесь с понятиями **пространство состояний, пространство действий и функция вознаграждения**, используемые для обучения Хагги.\n",
        "- Научите **своего собственного Хагги** приносить палку.\n",
        "- Получите возможность играть **со своим обученным Huggy прямо в вашем браузере**.\n",
        "\n"
      ],
      "metadata": {
        "id": "KK8GlyE0V1fz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Этот блокнот взят из курса обучения с глубоким подкреплением\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/deep-rl-course-illustration.jpg\" alt=\"Deep RL Course illustration\" width=\"50%\"/>"
      ],
      "metadata": {
        "id": "Cl4kUMIKbYCt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В этом бесплатном курсе вы будете:\n",
        "\n",
        "- 📖 Изучите глубокое обучение с подкреплением в **теории и практике**.\n",
        "- 🧑‍💻 Научитесь **использовать известные библиотеки Deep RL**, такие как Stable Baselines3, RL Baselines3 Zoo, CleanRL and Sample Factory 2.0.\n",
        "- 🤖 Обучайте **агентов в уникальных условиях** \n",
        "\n",
        "И еще проверьте учебную 📚 программу 👉 https://simoninithomas.github.io/deep-rl-course\n",
        "\n",
        "The best way to keep in touch is to join our discord server to exchange with the community and with us 👉🏻 https://discord.gg/ydHrjt3WP5"
      ],
      "metadata": {
        "id": "IaDAF3f5brCk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Предпосылки 🏗️\n",
        "\n",
        "Прежде чем погрузиться в блокнот, вам нужно:\n",
        "\n",
        "🔲 📚 **Развить понимание основ обучения с подкреплением** (MC, TD, Rewards hypothesis...) выполняя блок 1\n",
        "\n",
        "🔲 📚 **Прочитать введение к Huggy**, выполнив бонусный блок 1"
      ],
      "metadata": {
        "id": "te9C8mmQdkdL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Установите графический процессор 💪\n",
        "- Чтобы **ускорить обучение агента, мы будем использовать графический процессор**. Чтобы сделать это, перейдите к `Runtime > Change Runtime type`\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/gpu-step1.jpg\" alt=\"GPU Step 1\" width=\"40%\">"
      ],
      "metadata": {
        "id": "wHKRyzjbeLqL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `Hardware Accelerator > GPU`\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/gpu-step2.jpg\" alt=\"GPU Step 2\" width=\"30%\">"
      ],
      "metadata": {
        "id": "yX1IfhZEfM8S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Клонируйте репозиторий и установите зависимости 🔽\n",
        "\n",
        "- Нам нужно клонировать репозиторий, который **содержит экспериментальную версию библиотеки, которая позволяет вам отправлять вашего обученного агента в концентратор (Hub).**"
      ],
      "metadata": {
        "id": "hgbUZsd0fVjR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# Клонирование этого конкретного репозитория (может занять 3 минуты)\n",
        "!git clone https://github.com/huggingface/ml-agents/"
      ],
      "metadata": {
        "id": "IEy0gW78flcQ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# Зайдите в репозиторий и установите пакет (может занять 3 минуты)\n",
        "%cd ml-agents\n",
        "!pip3 install -e ./ml-agents-envs\n",
        "!pip3 install -e ./ml-agents"
      ],
      "metadata": {
        "id": "mNmHmWXpjjRG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Загрузите и переместите zip-файл среды в `./trained-envs-executables/linux/`\n",
        "\n",
        "- Исполняемый файл нашей среды находится в zip-файле.\n",
        "- Нам нужно загрузить его и разместить на `./trained-envs-executables/linux/`"
      ],
      "metadata": {
        "id": "DkHZmkckj6h7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ./trained-envs-executables\n",
        "!mkdir ./trained-envs-executables/linux"
      ],
      "metadata": {
        "id": "C6r85ZRBkXzb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1zv3M95ZJTWHUVOWT6ckq_cm98nft8gdF' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1zv3M95ZJTWHUVOWT6ckq_cm98nft8gdF\" -O ./trained-envs-executables/linux/Huggy.zip && rm -rf /tmp/cookies.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mz6lYW_7kdks",
        "outputId": "921e1332-ffbb-4139-ca56-5f2b361ce271"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-11 08:59:45--  https://docs.google.com/uc?export=download&confirm=t&id=1zv3M95ZJTWHUVOWT6ckq_cm98nft8gdF\n",
            "Resolving docs.google.com (docs.google.com)... 108.177.119.138, 108.177.119.113, 108.177.119.101, ...\n",
            "Connecting to docs.google.com (docs.google.com)|108.177.119.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-0k-28-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/jb0pb5rp4scgn6oeuukrqp4h6k4t5vle/1673427525000/15803371278684422230/*/1zv3M95ZJTWHUVOWT6ckq_cm98nft8gdF?e=download&uuid=e9ad69de-2a4f-40bd-a3aa-3cce6b7f04e7 [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2023-01-11 08:59:46--  https://doc-0k-28-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/jb0pb5rp4scgn6oeuukrqp4h6k4t5vle/1673427525000/15803371278684422230/*/1zv3M95ZJTWHUVOWT6ckq_cm98nft8gdF?e=download&uuid=e9ad69de-2a4f-40bd-a3aa-3cce6b7f04e7\n",
            "Resolving doc-0k-28-docs.googleusercontent.com (doc-0k-28-docs.googleusercontent.com)... 108.177.126.132, 2a00:1450:4013:c01::84\n",
            "Connecting to doc-0k-28-docs.googleusercontent.com (doc-0k-28-docs.googleusercontent.com)|108.177.126.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 39214997 (37M) [application/x-zip-compressed]\n",
            "Saving to: ‘./trained-envs-executables/linux/Huggy.zip’\n",
            "\n",
            "./trained-envs-exec 100%[===================>]  37.40M   117MB/s    in 0.3s    \n",
            "\n",
            "2023-01-11 08:59:46 (117 MB/s) - ‘./trained-envs-executables/linux/Huggy.zip’ saved [39214997/39214997]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загрузите файл Huggy.zip с https://drive.google.com/uc?export=download&id=1zv3M95ZJTWHUVOWT6ckq_cm98nft8gdF с помощью `wget`. Ознакомьтесь с полным решением для загрузки больших файлов из GDrive [здесь](https://bcrf.biochem.wisc.edu/2021/02/05/download-google-drive-files-using-wget/)"
      ],
      "metadata": {
        "id": "CCvPM-xvks7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!unzip -d ./trained-envs-executables/linux/ ./trained-envs-executables/linux/Huggy.zip"
      ],
      "metadata": {
        "id": "rMalXiAclVCU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Убедитесь, что ваш файл доступен"
      ],
      "metadata": {
        "id": "HKX9LwBeldMj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod -R 755 ./trained-envs-executables/linux/Huggy"
      ],
      "metadata": {
        "id": "IuxfllHclhLD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Давайте кратко рассмотрим, как работает эта среда\n",
        "\n",
        "### Пространство состояний: что \"воспринимает\" Хагги.\n",
        "\n",
        "Хагги не \"видит\" свое окружение. Вместо этого мы предоставляем ему информацию об окружающей среде:\n",
        "\n",
        "- Положение мишени (палки)\n",
        "- Относительное положение Хагги и цели\n",
        "- Ориентация его ног.\n",
        "\n",
        "Учитывая всю эту информацию, Хагги **может решить, какие действия предпринять дальше, чтобы достичь своей цели**.\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/unit-bonus1/huggy.jpg\" alt=\"Huggy\" width=\"70%\">\n",
        "\n",
        "\n",
        "### Пространство действия: какие движения может делать Хагги\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/unit-bonus1/huggy-action.jpg\" alt=\"Huggy action\" width=\"70%\">\n",
        "\n",
        "**Суставные двигатели приводят в движение ноги Хагги**. Это означает, что для достижения цели он должен **научиться правильно вращать суставные двигатели каждой из своих ног, чтобы двигаться**.\n",
        "\n",
        "### Функция вознаграждения\n",
        "\n",
        "Функция вознаграждения разработана таким образом, чтобы **Хагги выполнил свою цель**: принес палку.\n",
        "\n",
        "Помните, что одной из основ обучения с подкреплением является *гипотеза вознаграждения*: цель может быть описана как **максимизация ожидаемого совокупного вознаграждения**.\n",
        "\n",
        "Наша цель состоит в том, чтобы Хагги **шел к палке, но не слишком сильно вращался**. Следовательно, наша функция вознаграждения должна транслировать эту цель.\n",
        "\n",
        "Наша функция вознаграждения:\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/unit-bonus1/reward.jpg\" alt=\"Huggy reward function\" width=\"70%\">\n",
        "\n",
        "- *Бонус за ориентацию*: мы **вознаграждаем агента за то, что он приблизился к цели**.\n",
        "- *Штраф по времени*: штраф по фиксированному времени, назначаемый за каждое действие, чтобы **заставить его добраться до цели как можно быстрее**.\n",
        "- *Штраф за вращение*: мы наказываем Хагги, если **он слишком сильно вращается и поворачивается слишком быстро**.\n",
        "- *Награда за достижение цели*: мы вознаграждаем Хагги за **достижение цели**."
      ],
      "metadata": {
        "id": "qPbu8hNmlmTj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Проверьте конфигурационный файл Хагги\n",
        "\n",
        "- В ML-Agents гиперпараметры обучения определяются  **в файле config.yaml.**\n",
        "\n",
        "- В рамках этого блокнота мы не собираемся изменять гиперпараметры, но если вы хотите попробовать в качестве эксперимента, вам следует попробовать изменить некоторые гиперпараметры, Unity предоставляет очень [хорошую документацию, объясняющую каждый из них здесь](https://github.com/Unity-Technologies/ml-agents/blob/main/docs/Training-Configuration-File.md)."
      ],
      "metadata": {
        "id": "59enGsX-wPsw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **В случае, если вы хотите изменить гиперпараметры**, в записной книжке Google Colab вы можете открыть config.yaml: `/content/ml-agents/config/ppo/Huggy.yaml`\n",
        "\n",
        "- Например, **если вы хотите сохранить больше моделей во время обучения** (на данный момент мы сохраняем каждые 200 000 временных шагов обучения). Вам нужно изменить:\n",
        "  - `checkpoint_interval`: количество временных шагов обучения, между каждой контрольной точкой.\n",
        "  - `keep_checkpoints`: максимальное количество контрольных точек для сохранения модели.\n",
        "\n",
        "=> Просто имейте в виду, что **уменьшение значения `checkpoint_interval` означает больше моделей для загрузки в концентратор и, следовательно, более длительное время загрузки**\n",
        "\n",
        "Теперь мы готовы обучить нашего агента 🔥 ."
      ],
      "metadata": {
        "id": "mksk7Hc6x2yY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Обучите нашего агента\n",
        "\n",
        "Чтобы обучить нашего агента, нам просто нужно **запустить mlagents-learn и выбрать исполняемый файл, содержащий среду.**\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/unit-bonus1/mllearn.png\" alt=\"ml learn function\" width=\"70%\">\n",
        "\n",
        " С ML Agents, мы запускаем обучающий сценарий. Мы определяем четыре параметра:\n",
        "\n",
        "1. `mlagents-learn <config>`: путь, по которому находится конфигурационный файл гиперпараметров.\n",
        "2. `--env`: где находится исполняемый файл среды.\n",
        "3. `--run_id`: имя, которое вы хотите присвоить своему идентификатору тренировочного прогона.\n",
        "4. `--no-graphics`: чтобы не запускать визуализацию во время тренировки.\n",
        "\n",
        "Обучите модель и используйте флаг `--resume`, чтобы продолжить обучение в случае прерывания.\n",
        "\n",
        "> При первом использовании `--resume` произойдет сбой, попробуйте запустить блок еще раз, чтобы обойти ошибку."
      ],
      "metadata": {
        "id": "7HzhERC-y71n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Тренировка займет от 30 до 45 минут в зависимости от вашей машины (не забудьте **настроить графический процессор**). ☕️"
      ],
      "metadata": {
        "id": "-RSlgpgf0Pkm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mlagents-learn ./config/ppo/Huggy.yaml --env=./trained-envs-executables/linux/Huggy/Huggy --run-id=\"Huggy\" --no-graphics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNykFASY0ujD",
        "outputId": "e79750f3-d012-4aab-9b62-7e0533b11526"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "            ┐  ╖\n",
            "        ╓╖╬│╡  ││╬╖╖\n",
            "    ╓╖╬│││││┘  ╬│││││╬╖\n",
            " ╖╬│││││╬╜        ╙╬│││││╖╖                               ╗╗╗\n",
            " ╬╬╬╬╖││╦╖        ╖╬││╗╣╣╣╬      ╟╣╣╬    ╟╣╣╣             ╜╜╜  ╟╣╣\n",
            " ╬╬╬╬╬╬╬╬╖│╬╖╖╓╬╪│╓╣╣╣╣╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╒╣╣╖╗╣╣╣╗   ╣╣╣ ╣╣╣╣╣╣ ╟╣╣╖   ╣╣╣\n",
            " ╬╬╬╬┐  ╙╬╬╬╬│╓╣╣╣╝╜  ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╣╙ ╙╣╣╣  ╣╣╣ ╙╟╣╣╜╙  ╫╣╣  ╟╣╣\n",
            " ╬╬╬╬┐     ╙╬╬╣╣      ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣     ╣╣╣┌╣╣╜\n",
            " ╬╬╬╜       ╬╬╣╣      ╙╝╣╣╬      ╙╣╣╣╗╖╓╗╣╣╣╜ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣╦╓    ╣╣╣╣╣\n",
            " ╙   ╓╦╖    ╬╬╣╣   ╓╗╗╖            ╙╝╣╣╣╣╝╜   ╘╝╝╜   ╝╝╝  ╝╝╝   ╙╣╣╣    ╟╣╣╣\n",
            "   ╩╬╬╬╬╬╬╦╦╬╬╣╣╗╣╣╣╣╣╣╣╝                                             ╫╣╣╣╣\n",
            "      ╙╬╬╬╬╬╬╬╣╣╣╣╣╣╝╜\n",
            "          ╙╬╬╬╣╣╣╜\n",
            "             ╙\n",
            "        \n",
            " Version information:\n",
            "  ml-agents: 0.29.0.dev0,\n",
            "  ml-agents-envs: 0.29.0.dev0,\n",
            "  Communicator API: 1.5.0,\n",
            "  PyTorch: 1.8.1+cu102\n",
            "[INFO] Connected to Unity environment with package version 2.2.1-exp.1 and communication version 1.5.0\n",
            "[INFO] Connected new brain: Huggy?team=0\n",
            "[INFO] Hyperparameters for behavior name Huggy: \n",
            "\ttrainer_type:\tppo\n",
            "\thyperparameters:\t\n",
            "\t  batch_size:\t2048\n",
            "\t  buffer_size:\t20480\n",
            "\t  learning_rate:\t0.0003\n",
            "\t  beta:\t0.005\n",
            "\t  epsilon:\t0.2\n",
            "\t  lambd:\t0.95\n",
            "\t  num_epoch:\t3\n",
            "\t  learning_rate_schedule:\tlinear\n",
            "\t  beta_schedule:\tlinear\n",
            "\t  epsilon_schedule:\tlinear\n",
            "\tnetwork_settings:\t\n",
            "\t  normalize:\tTrue\n",
            "\t  hidden_units:\t512\n",
            "\t  num_layers:\t3\n",
            "\t  vis_encode_type:\tsimple\n",
            "\t  memory:\tNone\n",
            "\t  goal_conditioning_type:\thyper\n",
            "\t  deterministic:\tFalse\n",
            "\treward_signals:\t\n",
            "\t  extrinsic:\t\n",
            "\t    gamma:\t0.995\n",
            "\t    strength:\t1.0\n",
            "\t    network_settings:\t\n",
            "\t      normalize:\tFalse\n",
            "\t      hidden_units:\t128\n",
            "\t      num_layers:\t2\n",
            "\t      vis_encode_type:\tsimple\n",
            "\t      memory:\tNone\n",
            "\t      goal_conditioning_type:\thyper\n",
            "\t      deterministic:\tFalse\n",
            "\tinit_path:\tNone\n",
            "\tkeep_checkpoints:\t15\n",
            "\tcheckpoint_interval:\t200000\n",
            "\tmax_steps:\t2000000\n",
            "\ttime_horizon:\t1000\n",
            "\tsummary_freq:\t50000\n",
            "\tthreaded:\tFalse\n",
            "\tself_play:\tNone\n",
            "\tbehavioral_cloning:\tNone\n",
            "INFO:mlagents.trainers.stats:Hyperparameters for behavior name Huggy: \n",
            "\ttrainer_type:\tppo\n",
            "\thyperparameters:\t\n",
            "\t  batch_size:\t2048\n",
            "\t  buffer_size:\t20480\n",
            "\t  learning_rate:\t0.0003\n",
            "\t  beta:\t0.005\n",
            "\t  epsilon:\t0.2\n",
            "\t  lambd:\t0.95\n",
            "\t  num_epoch:\t3\n",
            "\t  learning_rate_schedule:\tlinear\n",
            "\t  beta_schedule:\tlinear\n",
            "\t  epsilon_schedule:\tlinear\n",
            "\tnetwork_settings:\t\n",
            "\t  normalize:\tTrue\n",
            "\t  hidden_units:\t512\n",
            "\t  num_layers:\t3\n",
            "\t  vis_encode_type:\tsimple\n",
            "\t  memory:\tNone\n",
            "\t  goal_conditioning_type:\thyper\n",
            "\t  deterministic:\tFalse\n",
            "\treward_signals:\t\n",
            "\t  extrinsic:\t\n",
            "\t    gamma:\t0.995\n",
            "\t    strength:\t1.0\n",
            "\t    network_settings:\t\n",
            "\t      normalize:\tFalse\n",
            "\t      hidden_units:\t128\n",
            "\t      num_layers:\t2\n",
            "\t      vis_encode_type:\tsimple\n",
            "\t      memory:\tNone\n",
            "\t      goal_conditioning_type:\thyper\n",
            "\t      deterministic:\tFalse\n",
            "\tinit_path:\tNone\n",
            "\tkeep_checkpoints:\t15\n",
            "\tcheckpoint_interval:\t200000\n",
            "\tmax_steps:\t2000000\n",
            "\ttime_horizon:\t1000\n",
            "\tsummary_freq:\t50000\n",
            "\tthreaded:\tFalse\n",
            "\tself_play:\tNone\n",
            "\tbehavioral_cloning:\tNone\n",
            "[INFO] Huggy. Step: 50000. Time Elapsed: 65.823 s. Mean Reward: 1.837. Std of Reward: 0.766. Training.\n",
            "INFO:mlagents.trainers.stats:Huggy. Step: 50000. Time Elapsed: 65.823 s. Mean Reward: 1.837. Std of Reward: 0.766. Training.\n",
            "[INFO] Huggy. Step: 100000. Time Elapsed: 119.671 s. Mean Reward: 2.550. Std of Reward: 1.121. Training.\n",
            "INFO:mlagents.trainers.stats:Huggy. Step: 100000. Time Elapsed: 119.671 s. Mean Reward: 2.550. Std of Reward: 1.121. Training.\n",
            "[INFO] Huggy. Step: 150000. Time Elapsed: 176.841 s. Mean Reward: 3.099. Std of Reward: 1.224. Training.\n",
            "INFO:mlagents.trainers.stats:Huggy. Step: 150000. Time Elapsed: 176.841 s. Mean Reward: 3.099. Std of Reward: 1.224. Training.\n",
            "[INFO] Huggy. Step: 200000. Time Elapsed: 234.681 s. Mean Reward: 3.201. Std of Reward: 1.467. Training.\n",
            "INFO:mlagents.trainers.stats:Huggy. Step: 200000. Time Elapsed: 234.681 s. Mean Reward: 3.201. Std of Reward: 1.467. Training.\n",
            "[INFO] Exported results/Huggy/Huggy/Huggy-199776.onnx\n",
            "INFO:mlagents.trainers.torch.model_serialization:Exported results/Huggy/Huggy/Huggy-199776.onnx\n",
            "[INFO] Huggy. Step: 250000. Time Elapsed: 292.459 s. Mean Reward: 3.470. Std of Reward: 1.697. Training.\n",
            "INFO:mlagents.trainers.stats:Huggy. Step: 250000. Time Elapsed: 292.459 s. Mean Reward: 3.470. Std of Reward: 1.697. Training.\n",
            "[INFO] Huggy. Step: 300000. Time Elapsed: 346.769 s. Mean Reward: 3.635. Std of Reward: 2.052. Training.\n",
            "INFO:mlagents.trainers.stats:Huggy. Step: 300000. Time Elapsed: 346.769 s. Mean Reward: 3.635. Std of Reward: 2.052. Training.\n",
            "[INFO] Huggy. Step: 350000. Time Elapsed: 402.473 s. Mean Reward: 3.460. Std of Reward: 1.817. Training.\n",
            "INFO:mlagents.trainers.stats:Huggy. Step: 350000. Time Elapsed: 402.473 s. Mean Reward: 3.460. Std of Reward: 1.817. Training.\n",
            "[INFO] Huggy. Step: 400000. Time Elapsed: 460.644 s. Mean Reward: 3.514. Std of Reward: 1.930. Training.\n",
            "INFO:mlagents.trainers.stats:Huggy. Step: 400000. Time Elapsed: 460.644 s. Mean Reward: 3.514. Std of Reward: 1.930. Training.\n",
            "[INFO] Exported results/Huggy/Huggy/Huggy-399943.onnx\n",
            "INFO:mlagents.trainers.torch.model_serialization:Exported results/Huggy/Huggy/Huggy-399943.onnx\n",
            "[INFO] Huggy. Step: 450000. Time Elapsed: 518.580 s. Mean Reward: 3.581. Std of Reward: 2.010. Training.\n",
            "INFO:mlagents.trainers.stats:Huggy. Step: 450000. Time Elapsed: 518.580 s. Mean Reward: 3.581. Std of Reward: 2.010. Training.\n",
            "[INFO] Huggy. Step: 500000. Time Elapsed: 577.528 s. Mean Reward: 3.646. Std of Reward: 1.932. Training.\n",
            "INFO:mlagents.trainers.stats:Huggy. Step: 500000. Time Elapsed: 577.528 s. Mean Reward: 3.646. Std of Reward: 1.932. Training.\n",
            "[INFO] Huggy. Step: 550000. Time Elapsed: 632.856 s. Mean Reward: 3.709. Std of Reward: 1.982. Training.\n",
            "INFO:mlagents.trainers.stats:Huggy. Step: 550000. Time Elapsed: 632.856 s. Mean Reward: 3.709. Std of Reward: 1.982. Training.\n",
            "[INFO] Huggy. Step: 600000. Time Elapsed: 692.798 s. Mean Reward: 3.609. Std of Reward: 1.840. Training.\n",
            "INFO:mlagents.trainers.stats:Huggy. Step: 600000. Time Elapsed: 692.798 s. Mean Reward: 3.609. Std of Reward: 1.840. Training.\n",
            "[INFO] Exported results/Huggy/Huggy/Huggy-599941.onnx\n",
            "INFO:mlagents.trainers.torch.model_serialization:Exported results/Huggy/Huggy/Huggy-599941.onnx\n",
            "[INFO] Huggy. Step: 650000. Time Elapsed: 748.205 s. Mean Reward: 3.596. Std of Reward: 1.993. Training.\n",
            "INFO:mlagents.trainers.stats:Huggy. Step: 650000. Time Elapsed: 748.205 s. Mean Reward: 3.596. Std of Reward: 1.993. Training.\n",
            "[INFO] Huggy. Step: 700000. Time Elapsed: 806.441 s. Mean Reward: 3.569. Std of Reward: 2.021. Training.\n",
            "INFO:mlagents.trainers.stats:Huggy. Step: 700000. Time Elapsed: 806.441 s. Mean Reward: 3.569. Std of Reward: 2.021. Training.\n",
            "[INFO] Huggy. Step: 750000. Time Elapsed: 865.429 s. Mean Reward: 3.692. Std of Reward: 2.030. Training.\n",
            "INFO:mlagents.trainers.stats:Huggy. Step: 750000. Time Elapsed: 865.429 s. Mean Reward: 3.692. Std of Reward: 2.030. Training.\n",
            "[INFO] Huggy. Step: 800000. Time Elapsed: 921.581 s. Mean Reward: 3.725. Std of Reward: 2.016. Training.\n",
            "INFO:mlagents.trainers.stats:Huggy. Step: 800000. Time Elapsed: 921.581 s. Mean Reward: 3.725. Std of Reward: 2.016. Training.\n",
            "[INFO] Exported results/Huggy/Huggy/Huggy-799992.onnx\n",
            "INFO:mlagents.trainers.torch.model_serialization:Exported results/Huggy/Huggy/Huggy-799992.onnx\n",
            "[INFO] Huggy. Step: 850000. Time Elapsed: 981.637 s. Mean Reward: 3.683. Std of Reward: 1.858. Training.\n",
            "INFO:mlagents.trainers.stats:Huggy. Step: 850000. Time Elapsed: 981.637 s. Mean Reward: 3.683. Std of Reward: 1.858. Training.\n",
            "[INFO] Huggy. Step: 900000. Time Elapsed: 1037.014 s. Mean Reward: 3.654. Std of Reward: 1.969. Training.\n",
            "INFO:mlagents.trainers.stats:Huggy. Step: 900000. Time Elapsed: 1037.014 s. Mean Reward: 3.654. Std of Reward: 1.969. Training.\n",
            "[INFO] Huggy. Step: 950000. Time Elapsed: 1098.365 s. Mean Reward: 3.698. Std of Reward: 2.024. Training.\n",
            "INFO:mlagents.trainers.stats:Huggy. Step: 950000. Time Elapsed: 1098.365 s. Mean Reward: 3.698. Std of Reward: 2.024. Training.\n",
            "[INFO] Huggy. Step: 1000000. Time Elapsed: 1154.795 s. Mean Reward: 3.490. Std of Reward: 1.993. Training.\n",
            "INFO:mlagents.trainers.stats:Huggy. Step: 1000000. Time Elapsed: 1154.795 s. Mean Reward: 3.490. Std of Reward: 1.993. Training.\n",
            "[INFO] Exported results/Huggy/Huggy/Huggy-999899.onnx\n",
            "INFO:mlagents.trainers.torch.model_serialization:Exported results/Huggy/Huggy/Huggy-999899.onnx\n",
            "[INFO] Huggy. Step: 1050000. Time Elapsed: 1210.117 s. Mean Reward: 3.664. Std of Reward: 2.032. Training.\n",
            "INFO:mlagents.trainers.stats:Huggy. Step: 1050000. Time Elapsed: 1210.117 s. Mean Reward: 3.664. Std of Reward: 2.032. Training.\n",
            "[INFO] Huggy. Step: 1100000. Time Elapsed: 1269.127 s. Mean Reward: 3.652. Std of Reward: 2.060. Training.\n",
            "INFO:mlagents.trainers.stats:Huggy. Step: 1100000. Time Elapsed: 1269.127 s. Mean Reward: 3.652. Std of Reward: 2.060. Training.\n",
            "[INFO] Huggy. Step: 1150000. Time Elapsed: 1324.718 s. Mean Reward: 3.712. Std of Reward: 2.067. Training.\n",
            "INFO:mlagents.trainers.stats:Huggy. Step: 1150000. Time Elapsed: 1324.718 s. Mean Reward: 3.712. Std of Reward: 2.067. Training.\n",
            "[INFO] Huggy. Step: 1200000. Time Elapsed: 1384.894 s. Mean Reward: 3.649. Std of Reward: 1.961. Training.\n",
            "INFO:mlagents.trainers.stats:Huggy. Step: 1200000. Time Elapsed: 1384.894 s. Mean Reward: 3.649. Std of Reward: 1.961. Training.\n",
            "[INFO] Exported results/Huggy/Huggy/Huggy-1199900.onnx\n",
            "INFO:mlagents.trainers.torch.model_serialization:Exported results/Huggy/Huggy/Huggy-1199900.onnx\n",
            "[INFO] Huggy. Step: 1250000. Time Elapsed: 1441.438 s. Mean Reward: 3.587. Std of Reward: 2.047. Training.\n",
            "INFO:mlagents.trainers.stats:Huggy. Step: 1250000. Time Elapsed: 1441.438 s. Mean Reward: 3.587. Std of Reward: 2.047. Training.\n",
            "[INFO] Huggy. Step: 1300000. Time Elapsed: 1500.020 s. Mean Reward: 3.714. Std of Reward: 2.032. Training.\n",
            "INFO:mlagents.trainers.stats:Huggy. Step: 1300000. Time Elapsed: 1500.020 s. Mean Reward: 3.714. Std of Reward: 2.032. Training.\n",
            "[INFO] Huggy. Step: 1350000. Time Elapsed: 1555.868 s. Mean Reward: 3.681. Std of Reward: 1.944. Training.\n",
            "INFO:mlagents.trainers.stats:Huggy. Step: 1350000. Time Elapsed: 1555.868 s. Mean Reward: 3.681. Std of Reward: 1.944. Training.\n",
            "[INFO] Huggy. Step: 1400000. Time Elapsed: 1612.460 s. Mean Reward: 3.693. Std of Reward: 1.998. Training.\n",
            "INFO:mlagents.trainers.stats:Huggy. Step: 1400000. Time Elapsed: 1612.460 s. Mean Reward: 3.693. Std of Reward: 1.998. Training.\n",
            "[INFO] Exported results/Huggy/Huggy/Huggy-1399969.onnx\n",
            "INFO:mlagents.trainers.torch.model_serialization:Exported results/Huggy/Huggy/Huggy-1399969.onnx\n",
            "[INFO] Huggy. Step: 1450000. Time Elapsed: 1671.195 s. Mean Reward: 3.781. Std of Reward: 2.000. Training.\n",
            "INFO:mlagents.trainers.stats:Huggy. Step: 1450000. Time Elapsed: 1671.195 s. Mean Reward: 3.781. Std of Reward: 2.000. Training.\n",
            "[INFO] Huggy. Step: 1500000. Time Elapsed: 1728.864 s. Mean Reward: 3.714. Std of Reward: 2.042. Training.\n",
            "INFO:mlagents.trainers.stats:Huggy. Step: 1500000. Time Elapsed: 1728.864 s. Mean Reward: 3.714. Std of Reward: 2.042. Training.\n",
            "[INFO] Huggy. Step: 1550000. Time Elapsed: 1790.210 s. Mean Reward: 3.834. Std of Reward: 2.034. Training.\n",
            "INFO:mlagents.trainers.stats:Huggy. Step: 1550000. Time Elapsed: 1790.210 s. Mean Reward: 3.834. Std of Reward: 2.034. Training.\n",
            "[INFO] Huggy. Step: 1600000. Time Elapsed: 1845.533 s. Mean Reward: 3.609. Std of Reward: 2.136. Training.\n",
            "INFO:mlagents.trainers.stats:Huggy. Step: 1600000. Time Elapsed: 1845.533 s. Mean Reward: 3.609. Std of Reward: 2.136. Training.\n",
            "[INFO] Exported results/Huggy/Huggy/Huggy-1599965.onnx\n",
            "INFO:mlagents.trainers.torch.model_serialization:Exported results/Huggy/Huggy/Huggy-1599965.onnx\n",
            "[INFO] Huggy. Step: 1650000. Time Elapsed: 1905.870 s. Mean Reward: 3.477. Std of Reward: 2.139. Training.\n",
            "INFO:mlagents.trainers.stats:Huggy. Step: 1650000. Time Elapsed: 1905.870 s. Mean Reward: 3.477. Std of Reward: 2.139. Training.\n",
            "[INFO] Huggy. Step: 1700000. Time Elapsed: 1961.887 s. Mean Reward: 3.489. Std of Reward: 2.232. Training.\n",
            "INFO:mlagents.trainers.stats:Huggy. Step: 1700000. Time Elapsed: 1961.887 s. Mean Reward: 3.489. Std of Reward: 2.232. Training.\n",
            "[INFO] Huggy. Step: 1750000. Time Elapsed: 2020.236 s. Mean Reward: 3.531. Std of Reward: 2.285. Training.\n",
            "INFO:mlagents.trainers.stats:Huggy. Step: 1750000. Time Elapsed: 2020.236 s. Mean Reward: 3.531. Std of Reward: 2.285. Training.\n",
            "[INFO] Huggy. Step: 1800000. Time Elapsed: 2079.925 s. Mean Reward: 3.562. Std of Reward: 2.270. Training.\n",
            "INFO:mlagents.trainers.stats:Huggy. Step: 1800000. Time Elapsed: 2079.925 s. Mean Reward: 3.562. Std of Reward: 2.270. Training.\n",
            "[INFO] Exported results/Huggy/Huggy/Huggy-1799963.onnx\n",
            "INFO:mlagents.trainers.torch.model_serialization:Exported results/Huggy/Huggy/Huggy-1799963.onnx\n",
            "[INFO] Huggy. Step: 1850000. Time Elapsed: 2136.490 s. Mean Reward: 3.521. Std of Reward: 2.246. Training.\n",
            "INFO:mlagents.trainers.stats:Huggy. Step: 1850000. Time Elapsed: 2136.490 s. Mean Reward: 3.521. Std of Reward: 2.246. Training.\n",
            "[INFO] Huggy. Step: 1900000. Time Elapsed: 2199.878 s. Mean Reward: 3.582. Std of Reward: 2.256. Training.\n",
            "INFO:mlagents.trainers.stats:Huggy. Step: 1900000. Time Elapsed: 2199.878 s. Mean Reward: 3.582. Std of Reward: 2.256. Training.\n",
            "[INFO] Huggy. Step: 1950000. Time Elapsed: 2256.991 s. Mean Reward: 3.615. Std of Reward: 2.356. Training.\n",
            "INFO:mlagents.trainers.stats:Huggy. Step: 1950000. Time Elapsed: 2256.991 s. Mean Reward: 3.615. Std of Reward: 2.356. Training.\n",
            "[INFO] Huggy. Step: 2000000. Time Elapsed: 2323.041 s. Mean Reward: 3.632. Std of Reward: 2.263. Training.\n",
            "INFO:mlagents.trainers.stats:Huggy. Step: 2000000. Time Elapsed: 2323.041 s. Mean Reward: 3.632. Std of Reward: 2.263. Training.\n",
            "[INFO] Exported results/Huggy/Huggy/Huggy-1999391.onnx\n",
            "INFO:mlagents.trainers.torch.model_serialization:Exported results/Huggy/Huggy/Huggy-1999391.onnx\n",
            "[INFO] Exported results/Huggy/Huggy/Huggy-2000141.onnx\n",
            "INFO:mlagents.trainers.torch.model_serialization:Exported results/Huggy/Huggy/Huggy-2000141.onnx\n",
            "[INFO] Copied results/Huggy/Huggy/Huggy-2000141.onnx to results/Huggy/Huggy.onnx.\n",
            "INFO:mlagents.trainers.model_saver.torch_model_saver:Copied results/Huggy/Huggy/Huggy-2000141.onnx to results/Huggy/Huggy.onnx.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Перенос агента на 🤗 Hub\n",
        "\n",
        "- Теперь, когда мы обучили нашего агента, мы **готовы перенести его на хаб, чтобы иметь возможность играть с Huggy в браузере 🔥.**"
      ],
      "metadata": {
        "id": "fJQ7_U4Y03Yt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Чтобы иметь возможность поделиться своей моделью с сообществом, необходимо выполнить еще три шага:\n",
        "\n",
        "1️⃣ (Если это еще не сделано) создайте учетную запись для HF ➡ https://huggingface.co/join\n",
        "\n",
        "2️⃣ Войдите в систему, а затем вам нужно сохранить свой токен аутентификации с веб-сайта Hugging Face.\n",
        "- Создайте новый токен (https://huggingface.co/settings/tokens) **с разрешением на запись**\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/create-token.jpg\" alt=\"Create HF Token\" width=\"50%\">\n",
        "\n",
        "- Скопируйте токен \n",
        "- Запустите ячейку ниже и вставьте токен"
      ],
      "metadata": {
        "id": "xDLzz2Dz3oGa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331,
          "referenced_widgets": [
            "fb97f50548214899a1f76e7c9a5e162e",
            "a859c3c184df4e1db7ef0dd1099ba7cf",
            "84d1e0688de34a409b143fc8dafcd354",
            "730c6dd744e54685b5c3d791c0323460",
            "cbf6b9f7525647dcad31e9a43584ae33",
            "f34899b25b4b45b3bea9fc96e85c71da",
            "e6e8fbf9c5fe4f879b2edd9b2745be8b",
            "01d3fba2895d4ebdbfba95c4b71c2cce",
            "a6f39b55abd04923a48c3edee4531a89",
            "ebaeeb3aea0b47bc8d517bce004c2afe",
            "982154a224ee441db01676eda6df3ec7",
            "88f9f2038c41457cbba82bb7170dd8d9",
            "c313c022302f4947b4e83aa152952f64",
            "185f2fc502004bb98379b808f64c2b50",
            "38d67d4fc5ec47abad0f0e2c65c806c9",
            "480fd15273f4443d9eb6338cf4378de2",
            "85a4f7480de84fe89efe61c9fe0c9ab6"
          ]
        },
        "id": "Jx7faX_Y5FIJ",
        "outputId": "37809ecb-b550-4154-e94e-a8e5e85a11cb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token is valid.\n",
            "Your token has been saved in your configured git credential helpers (store).\n",
            "Your token has been saved to /root/.huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Если вы не хотите использовать записную книжку Google Colabora Jupyter, вам нужно вместо этого использовать эту команду: `huggingface-cli login`\n",
        "\n",
        "Или:\n",
        "\n",
        "`from huggingface_hub import login`\n",
        "\n",
        "`login(token=token, add_to_git_credential=True)`\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "I9BG4ddH5MNo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Затем нам просто нужно запустить `mlagents-push-to-hf`.\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/unit-bonus1/mlpush.png\" alt=\"ml learn function\" width=\"70%\">"
      ],
      "metadata": {
        "id": "QF30Hl2z6TVv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "И мы определяем 4 параметра:\n",
        "\n",
        "1. `--run-id`: имя идентификатора тренировочного прогона.\n",
        "2. `--local-dir`: там, где был сохранен агент, это `results/--run-id`, так что в нашем случае `results/Huggy`.\n",
        "3. `--repo-id`: название репозитория Hugging Face, которое вы хотите создать или обновить. Это your `\"huggingface username\"/\"the repo name\"`. Если репозиторий не существует **, он будет создан автоматически**\n",
        "4. `--commit-message`: поскольку репозитории HF являются репозиторием git, вам необходимо определить сообщение о фиксации."
      ],
      "metadata": {
        "id": "_cNoBOj36hLf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mlagents-push-to-hf --run-id=\"HuggyTraining\" --local-dir=\"./results/Huggy\" --repo-id=\"Art-phys/ppo-Huggy\" --commit-message=\"Huggy\""
      ],
      "metadata": {
        "id": "zJ7VmyIX9SB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Если все сработало, вы должны получить это в конце процесса (но с вашим URL-адресом 😆) :\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "Your model is pushed to the hub. You can view your model here: https://huggingface.co/ThomasSimonini/ppo-Huggy\n",
        "```\n",
        "\n",
        "Это ссылка на ваш репозиторий моделей. Репозиторий содержит карточку модели, которая объясняет, как использовать модель, ваши журналы Tensorboard и ваш конфигурационный файл. **это репозиторий git, что означает, что вы можете иметь разные коммиты, обновлять свой репозиторий новым нажатием, открывать запросы на извлечение и т.д.**\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/unit-bonus1/modelcard.png\" alt=\"ml learn function\" width=\"100%\">"
      ],
      "metadata": {
        "id": "Clv6hBMN9dRU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь приступаем к самому интересному:: **возможность играть с Huggy онлайн 👀.**"
      ],
      "metadata": {
        "id": "LqZtztjh-icj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Поиграй со своим Huggy 🐕\n",
        "\n",
        "Этот шаг самый простой:\n",
        "\n",
        "- Откройте игру Huggy в своем браузере: https://singularite.itch.io/huggy\n",
        "\n",
        "- Нажмите на `\"Load your Huggy model\"`\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/unit-bonus1/load-huggy.jpg\" alt=\"load-huggy\" width=\"70%\">"
      ],
      "metadata": {
        "id": "JzrxUvQn_Evz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. На шаге 1 выберите репозиторий вашей модели, который является идентификатором модели (в примере ThomasSimonini/ppo-Huggy).\n",
        "\n",
        "2. На шаге 2 **выберите, какую модель вы хотите воспроизвести**:\n",
        "  - У меня их несколько, так как мы сохраняли модель каждые 500000 временных шагов.\n",
        "  - Но так как я хочу более свежую, я выбираю `Huggy.onnx`\n",
        "\n",
        "👉Что приятно **,так это попробовать моделями с различными шагами, чтобы видеть улучшение агента.**"
      ],
      "metadata": {
        "id": "rSY7rRmyAX3h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Поздравляю с завершением этого бонусного блока!\n",
        "\n",
        "Теперь вы можете сидеть и наслаждаться игрой со своим Huggy 🐶 . И не ** забудьте поделиться любовью, поделившись Huggy со своими друзьями 🤗 **. И если вы поделитесь этим в социальных сетях, ** пожалуйста, отметьте нас @huggingface и меня @simoninithomas**\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/unit-bonus1/huggy-cover.jpeg\" alt=\"Huggy cover\" width=\"50%\">\n",
        "\n",
        "\n",
        "## Keep Learning, Stay  awesome 🤗 Продолжай учиться"
      ],
      "metadata": {
        "id": "v-CxcGniBXSR"
      }
    }
  ]
}